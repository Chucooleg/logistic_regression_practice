{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time, gc\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "\n",
    "from utils.moduleCodeProfiler import rankByCriteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 25 02:33:54 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 0000DF45:00:00.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    24W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.data_dir = '~/datadrive'\n",
    "args.dataset_dir = 'toy_mlp_1'\n",
    "args.seed = 123\n",
    "args.batch_size = 1000\n",
    "# https://stackoverflow.com/questions/15753701/how-can-i-pass-a-list-as-a-command-line-argument-with-argparse\n",
    "args.hidden_layer_dims = [50, 50, 50, 50, 50, 50, 50]\n",
    "args.lr = 0.01\n",
    "args.epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 training indices [1603 8472 2213  498 1038 8399 3324 7535 1519 1959]\n",
      "X shape (9000, 10)\n",
      "y shape (9000,)\n"
     ]
    }
   ],
   "source": [
    "# construct and save toydataset\n",
    "\n",
    "m_train = 9000\n",
    "m_total = m_train\n",
    "\n",
    "X, y = make_classification(n_samples=m_total, n_features=10, n_informative=10, n_redundant=0, n_repeated=0, n_classes=5, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=args.seed)\n",
    "# y = np.expand_dims(y, -1)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "permutation = np.random.permutation(m_total)\n",
    "print('First 10 training indices', permutation[:10])\n",
    "print('X shape', X.shape)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "train_indices = permutation[0:m_train]\n",
    "\n",
    "dataset_dir = 'toy_mlp_1'\n",
    "os.makedirs(os.path.join(args.data_dir, dataset_dir, 'train'), mode = 0o777, exist_ok = True) \n",
    "\n",
    "np.save(os.path.join(args.data_dir, dataset_dir, 'train', 'features.npy'), X[train_indices])\n",
    "np.save(os.path.join(args.data_dir, dataset_dir, 'train', 'labels.npy'), y[train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    \"\"\"Toy dataset construction.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (string): Path to the directory with data files.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        # shape (m, nx)\n",
    "        self.X = np.load(os.path.join(data_dir, 'features.npy'))\n",
    "        # shape (m, ny=1)\n",
    "        self.y = np.load(os.path.join(data_dir, 'labels.npy'))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        else:\n",
    "            X = torch.from_numpy(self.X[idx, :]).type(torch.FloatTensor)\n",
    "            y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "#             y = torch.from_numpy(self.y[idx, :]).type(torch.FloatTensor)\n",
    "            sample = {'X': X, 'y': y}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLazy(nn.Module):\n",
    "\n",
    "    def __init__(self, nx, hidden_layer_dims, ny):\n",
    "        super(MLPLazy, self).__init__()\n",
    "        self.hidden_layer_dims = hidden_layer_dims\n",
    "        \n",
    "        linear_layers = []\n",
    "        last_dim = nx\n",
    "        for next_dim in hidden_layer_dims:\n",
    "            linear_layer = nn.Linear(last_dim, next_dim)\n",
    "            linear_layers.append(linear_layer)\n",
    "            last_dim = next_dim\n",
    "        # should push to ModuleList so that params stay on cuda\n",
    "        self.linear_layers = nn.ModuleList(linear_layers)\n",
    "        self.scorer = nn.Linear(last_dim, ny)\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        X has shape (m, nx)\n",
    "        '''\n",
    "        last_X = X\n",
    "        for i, linear_layer in enumerate(self.linear_layers):\n",
    "            # shape (m, self.hidden_layer_dims[i])\n",
    "            last_X = linear_layer(last_X)\n",
    "            # shape (m, self.hidden_layer_dims[i])\n",
    "            last_X = torch.relu(last_X)\n",
    "        # shape (m, ny)\n",
    "        z = self.scorer(last_X)\n",
    "        # shape (m, ny)\n",
    "        a = torch.softmax(z, dim=1)\n",
    "        return z, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    global start_time\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "def end_timer():\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weights_precision(model):\n",
    "    '''specific to checking MLP'''\n",
    "    for i, layer in enumerate(model.linear_layers):\n",
    "        print(f'layer {i}, weight dtype {layer.weight.dtype}')\n",
    "        print(f'layer {i}, bias dtype {layer.bias.dtype}')\n",
    "    print(f'scorer weight dtype {model.scorer.weight.dtype}')\n",
    "    print(f'scorer bias dtype {model.scorer.bias.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_memory_alloc():\n",
    "    devices_max_memory_alloc = {}\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        device = torch.device(f'cuda:{i}')\n",
    "        devices_max_memory_alloc[f'cuda:{i}'] = torch.cuda.max_memory_allocated(device) / 1e6\n",
    "        torch.cuda.reset_max_memory_allocated(device)\n",
    "    return devices_max_memory_alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train(args, gpu=0, debug=False):\n",
    "\n",
    "    start_timer()\n",
    "    torch.manual_seed(args.seed)\n",
    "    \n",
    "    ################################################################\n",
    "    # load datasets\n",
    "    training_set = ToyDataset(data_dir=os.path.join(args.data_dir, args.dataset_dir, 'train'))\n",
    "    training_generator = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                                        batch_size=args.batch_size, \n",
    "                                                        shuffle=True, \n",
    "                                                        num_workers=0, \n",
    "                                                        pin_memory=True)\n",
    "\n",
    "    nx = training_set.X.shape[1]\n",
    "    ny = max(training_set.y) + 1\n",
    "    ################################################################\n",
    "\n",
    "    model = MLPLazy(nx, args.hidden_layer_dims, ny)  # single\n",
    "    loss_criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model.to(device=gpu)    \n",
    "\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=args.lr)  # half\n",
    "    if debug:\n",
    "        print('\\nmodel weights at init')\n",
    "        check_weights_precision(model)\n",
    "\n",
    "    history = {\n",
    "        'epoch_train_losses': [], 'step_train_losses': [], 'max_memory_allocation':[], \n",
    "         'timing': defaultdict(int)\n",
    "    }\n",
    "    history['timing']['setup'] += end_timer()\n",
    "    \n",
    "    loop_start_time = time.time()\n",
    "    \n",
    "    for e in range(5000):\n",
    "        start_timer()\n",
    "        model.train()\n",
    "        sum_batch_losses = torch.tensor([0.], dtype=torch.float, device=gpu)\n",
    "        all_batch_losses = []\n",
    "        batch_max_memory_alloc = []\n",
    "        history['timing']['epoch_setup'] += end_timer()\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        for batch_i, batch_data in enumerate(training_generator):\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            start_timer()\n",
    "            batch_max_memory_alloc.append(get_max_memory_alloc()['cuda:0'])\n",
    "            history['timing']['get_memory'] += end_timer()\n",
    "\n",
    "            start_timer()\n",
    "            batch_X = batch_data['X'].cuda(gpu, non_blocking=True) # single\n",
    "            batch_y = batch_data['y'].cuda(gpu, non_blocking=True) # long\n",
    "            history['timing']['data'] += end_timer()\n",
    "            \n",
    "            start_timer()\n",
    "            logits, activations = model(batch_X) # single\n",
    "            history['timing']['forward'] += end_timer()\n",
    "\n",
    "            start_timer()\n",
    "            loss = loss_criterion(logits, batch_y)  # single\n",
    "            history['timing']['loss'] += end_timer()\n",
    "            \n",
    "            start_timer()\n",
    "            opt.zero_grad()\n",
    "            history['timing']['zero_grad'] += end_timer()\n",
    "            \n",
    "            start_timer()\n",
    "            loss.backward()  # single\n",
    "            history['timing']['backward'] += end_timer()\n",
    "            \n",
    "            start_timer()\n",
    "            opt.step()\n",
    "            history['timing']['opt_step'] += end_timer()\n",
    "            \n",
    "            start_timer()\n",
    "            sum_batch_losses += loss\n",
    "            all_batch_losses.append(loss)\n",
    "            history['timing']['append_losses'] += end_timer()\n",
    "            \n",
    "            history['timing']['batch_time'] += time.time() - batch_start_time\n",
    "\n",
    "        start_timer()\n",
    "        num_batches = batch_i + 1.\n",
    "        history['epoch_train_losses'].append(sum_batch_losses/num_batches)\n",
    "        history['step_train_losses'] += all_batch_losses\n",
    "        history['max_memory_allocation'] += batch_max_memory_alloc\n",
    "        history['timing']['append'] += end_timer()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        history['timing']['epoch_end_time'] += time.time() - epoch_start_time\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    history['timing']['loop_end_time'] += time.time() - loop_start_time\n",
    "    \n",
    "    start_timer()\n",
    "    itemize = lambda x: [tensor_val.item() for tensor_val in x]\n",
    "    history['epoch_train_losses'] = itemize(history['epoch_train_losses'])   \n",
    "    history['step_train_losses'] = itemize(history['step_train_losses'])   \n",
    "    history['timing']['itemize_losses'] += end_timer()\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 25 02:34:03 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 0000DF45:00:00.0 Off |                    0 |\r\n",
      "| N/A   30C    P0    24W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model weights at init\n",
      "layer 0, weight dtype torch.float32\n",
      "layer 0, bias dtype torch.float32\n",
      "layer 1, weight dtype torch.float32\n",
      "layer 1, bias dtype torch.float32\n",
      "layer 2, weight dtype torch.float32\n",
      "layer 2, bias dtype torch.float32\n",
      "layer 3, weight dtype torch.float32\n",
      "layer 3, bias dtype torch.float32\n",
      "layer 4, weight dtype torch.float32\n",
      "layer 4, bias dtype torch.float32\n",
      "layer 5, weight dtype torch.float32\n",
      "layer 5, bias dtype torch.float32\n",
      "layer 6, weight dtype torch.float32\n",
      "layer 6, bias dtype torch.float32\n",
      "scorer weight dtype torch.float32\n",
      "scorer bias dtype torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/cuda/memory.py:234: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.559645652771\n"
     ]
    }
   ],
   "source": [
    "all_start_time = time.time()\n",
    "history, model = main_train(args, debug=True)\n",
    "torch.cuda.synchronize()\n",
    "print(time.time() - all_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model weights at init\n",
      "layer 0, weight dtype torch.float32\n",
      "layer 0, bias dtype torch.float32\n",
      "layer 1, weight dtype torch.float32\n",
      "layer 1, bias dtype torch.float32\n",
      "layer 2, weight dtype torch.float32\n",
      "layer 2, bias dtype torch.float32\n",
      "layer 3, weight dtype torch.float32\n",
      "layer 3, bias dtype torch.float32\n",
      "scorer weight dtype torch.float32\n",
      "scorer bias dtype torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/cuda/memory.py:234: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "with profiler.profile(profile_memory=True, record_shapes=True, use_cuda=False, with_stack=True) as prof:\n",
    "    with profiler.record_function(\"forward\"):\n",
    "        history, model = main_train(args, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'setup': 0.033419132232666016,\n",
       "             'epoch_setup': 0.05381584167480469,\n",
       "             'get_memory': 2.5898804664611816,\n",
       "             'data': 0.3465733528137207,\n",
       "             'forward': 3.9523918628692627,\n",
       "             'loss': 0.5222015380859375,\n",
       "             'zero_grad': 1.9296772480010986,\n",
       "             'backward': 4.9550769329071045,\n",
       "             'opt_step': 1.6817753314971924,\n",
       "             'append_losses': 0.136216402053833,\n",
       "             'batch_time': 16.47422170639038,\n",
       "             'append': 0.05046844482421875,\n",
       "             'epoch_end_time': 112.07442474365234,\n",
       "             'loop_end_time': 112.1322078704834,\n",
       "             'itemize_losses': 0.11670160293579102})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args.hidden_layer_dims = [10, 10, 10, 10, 10, 10, 10]\n",
    "# 500 epochs\"\n",
    "history['timing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiler Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked by cuda_memory_usage\n",
      "\n",
      "109.92 Mb\n",
      "##############################################\n",
      "model, aten::empty, forward, (26) last_X = torch.relu(last_X)\n",
      "13.89 Mb\n",
      "##############################################\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model, aten::relu, forward, (26) last_X = torch.relu(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model, aten::threshold, forward, (26) last_X = torch.relu(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model, ReluBackward0, forward, (26) last_X = torch.relu(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model, aten::threshold_backward, forward, (26) last_X = torch.relu(last_X)\n",
      "6.94 Mb\n",
      "##############################################\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "5.30 Mb\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "5.30 Mb\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "5.30 Mb\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "5.30 Mb\n",
      "##############################################\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "5.30 Mb\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "5.30 Mb\n",
      "##############################################\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "1.76 Mb\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "1.76 Mb\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "1.76 Mb\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "1.76 Mb\n",
      "##############################################\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "1.76 Mb\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "1.76 Mb\n",
      "##############################################\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model, aten::softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model, aten::_softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model, aten::empty_like, forward, (30) a = torch.softmax(z, dim=1)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model, aten::empty, forward, (30) a = torch.softmax(z, dim=1)\n",
      "900.00 Kb\n",
      "##############################################\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::contiguous, forward, (30) a = torch.softmax(z, dim=1)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "rankByCriteria(prof, model, criteria='cuda_memory_usage', per_thread=False, per_inp_shapes=False, include_external=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                aten::zeros         0.00%     364.803us         0.00%     699.006us     699.006us           4 b           0 b           0 b           0 b             1  \n",
      "                                aten::empty        12.21%        5.508s        12.21%        5.508s      60.304us     705.43 Kb     705.43 Kb      23.58 Mb      23.58 Mb         91342  \n",
      "                                aten::zero_         0.12%      54.524ms         0.18%      80.016ms     181.443us           0 b           0 b           0 b           0 b           441  \n",
      "                                aten::fill_         0.06%      28.510ms         0.06%      28.510ms      58.662us           0 b           0 b           0 b           0 b           486  \n",
      "                                    forward         5.42%        2.444s        99.89%       45.063s       45.063s          -4 b      -4.46 Mb      14.79 Mb      -3.89 Mb             1  \n",
      "                               aten::detach         0.00%     613.004us         0.00%       1.157ms     115.671us           0 b           0 b           0 b           0 b            10  \n",
      "                                     detach         0.00%     543.707us         0.00%     543.707us      54.371us           0 b           0 b           0 b           0 b            10  \n",
      "                             aten::uniform_         0.00%       1.370ms         0.00%       1.370ms     136.981us           0 b           0 b           0 b           0 b            10  \n",
      "                    aten::is_floating_point         0.01%       3.752ms         0.01%       3.752ms      53.596us           0 b           0 b           0 b           0 b            70  \n",
      "                                   aten::to        11.57%        5.217s        37.49%       16.911s     187.679us       1.72 Mb           0 b       2.09 Mb           0 b         90105  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 45.112s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                    forward         5.42%        2.444s        99.89%       45.063s       45.063s          -4 b      -4.46 Mb      14.79 Mb      -3.89 Mb             1  \n",
      "                                   aten::to        11.57%        5.217s        37.49%       16.911s     187.679us       1.72 Mb           0 b       2.09 Mb           0 b         90105  \n",
      "                                aten::stack         0.36%     163.401ms        27.42%       12.371s     137.454ms       2.06 Mb           0 b           0 b           0 b            90  \n",
      "                            aten::unsqueeze        10.79%        4.868s        21.29%        9.605s     106.720us           0 b           0 b           0 b           0 b         90000  \n",
      "                        aten::empty_strided        14.33%        6.464s        14.33%        6.464s     143.135us       1.72 Mb       1.72 Mb       2.12 Mb       2.12 Mb         45160  \n",
      "                                aten::empty        12.21%        5.508s        12.21%        5.508s      60.304us     705.43 Kb     705.43 Kb      23.58 Mb      23.58 Mb         91342  \n",
      "                                aten::copy_        11.62%        5.242s        11.63%        5.245s     116.024us           0 b           0 b           0 b           0 b         45205  \n",
      "                              aten::detach_         5.27%        2.378s        10.58%        4.772s     106.022us           0 b           0 b           0 b           0 b         45005  \n",
      "                           aten::as_strided        10.56%        4.764s        10.56%        4.764s      52.154us           0 b           0 b           0 b           0 b         91350  \n",
      "                                  aten::cat         0.03%      14.670ms         5.77%        2.603s      28.918ms       2.06 Mb           0 b           0 b           0 b            90  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 45.112s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked by cpu_time\n",
      "\n",
      "124.172s\n",
      "##############################################\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "226.190ms\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "226.190ms\n",
      "##############################################\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "48.934ms\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "48.934ms\n",
      "##############################################\n",
      "model, aten::relu, forward, (26) last_X = torch.relu(last_X)\n",
      "41.883ms\n",
      "##############################################\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "29.480ms\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "29.480ms\n",
      "##############################################\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "24.443ms\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "24.443ms\n",
      "##############################################\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "22.149ms\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "22.149ms\n",
      "##############################################\n",
      "model, aten::threshold, forward, (26) last_X = torch.relu(last_X)\n",
      "21.766ms\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "19.693ms\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "19.693ms\n",
      "##############################################\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "18.735ms\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "18.735ms\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "17.210ms\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "17.210ms\n",
      "##############################################\n",
      "model, aten::softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "15.777ms\n",
      "##############################################\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "14.134ms\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "14.134ms\n",
      "##############################################\n",
      "model, aten::_softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "12.986ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "10.895ms\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "10.895ms\n",
      "##############################################\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "10.241ms\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "10.241ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (26) last_X = torch.relu(last_X)\n",
      "10.124ms\n",
      "##############################################\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "9.219ms\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "9.219ms\n",
      "##############################################\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "7.228ms\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "7.228ms\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "7.013ms\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "7.013ms\n",
      "##############################################\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "5.812ms\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "5.812ms\n",
      "##############################################\n",
      "model, ReluBackward0, forward, (26) last_X = torch.relu(last_X)\n",
      "5.349ms\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "5.091ms\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "5.091ms\n",
      "##############################################\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "4.772ms\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "4.772ms\n",
      "##############################################\n",
      "model, aten::empty_like, forward, (30) a = torch.softmax(z, dim=1)\n",
      "4.594ms\n",
      "##############################################\n",
      "model, aten::threshold_backward, forward, (26) last_X = torch.relu(last_X)\n",
      "4.440ms\n",
      "##############################################\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "2.993ms\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "2.993ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "2.818ms\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "2.818ms\n",
      "##############################################\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "2.485ms\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "2.485ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (30) a = torch.softmax(z, dim=1)\n",
      "2.277ms\n",
      "##############################################\n",
      "model, aten::contiguous, forward, (30) a = torch.softmax(z, dim=1)\n",
      "2.126ms\n",
      "##############################################\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "1.899ms\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "1.899ms\n",
      "##############################################\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "666.604us\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "666.604us\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "rankByCriteria(prof, model, criteria='cpu_time', per_thread=False, per_inp_shapes=False, include_external=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked by cuda_time\n",
      "\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::relu, forward, (26) last_X = torch.relu(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::threshold, forward, (26) last_X = torch.relu(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::empty, forward, (26) last_X = torch.relu(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::_softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::contiguous, forward, (30) a = torch.softmax(z, dim=1)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::empty_like, forward, (30) a = torch.softmax(z, dim=1)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::empty, forward, (30) a = torch.softmax(z, dim=1)\n",
      "0.000us\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, ReluBackward0, forward, (26) last_X = torch.relu(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::threshold_backward, forward, (26) last_X = torch.relu(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.000us\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "rankByCriteria(prof, model, criteria='cuda_time', per_thread=False, per_inp_shapes=False, include_external=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_losses': [1.6124650239944458,\n",
       "  1.6124032735824585,\n",
       "  1.6123392581939697,\n",
       "  1.6122788190841675,\n",
       "  1.6122169494628906,\n",
       "  1.6121578216552734,\n",
       "  1.6120952367782593,\n",
       "  1.612037181854248,\n",
       "  1.6119766235351562,\n",
       "  1.6119177341461182],\n",
       " 'max_memory_allocation': [0.671744,\n",
       "  0.662016,\n",
       "  0.667136,\n",
       "  0.667648,\n",
       "  0.667648,\n",
       "  0.66816,\n",
       "  0.66816,\n",
       "  0.668672,\n",
       "  0.668672,\n",
       "  0.669184,\n",
       "  0.669184,\n",
       "  0.669696,\n",
       "  0.669696,\n",
       "  0.670208,\n",
       "  0.670208,\n",
       "  0.67072,\n",
       "  0.67072,\n",
       "  0.671232,\n",
       "  0.671232,\n",
       "  0.671744]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '32bit')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(history['step_train_losses'])), np.array(history['step_train_losses']))\n",
    "plt.title('32bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '32bit')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(history['epoch_train_losses'])), np.array(history['epoch_train_losses']))\n",
    "plt.title('32bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '32bit')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(history['max_memory_allocation'])), np.array(history['max_memory_allocation']))\n",
    "plt.title('32bit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 22 16:31:42 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 000047DD:00:00.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    56W / 149W |    338MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     24644      C   ...s/py37_pytorch/bin/python      335MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Ran without profiler\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |  496640 B  |  141505 KB |  141505 KB |\n",
      "|       from large pool |       0 B  |       0 B  |       0 KB |       0 KB |\n",
      "|       from small pool |       0 B  |  496640 B  |  141505 KB |  141505 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |  496640 B  |  141505 KB |  141505 KB |\n",
      "|       from large pool |       0 B  |       0 B  |       0 KB |       0 KB |\n",
      "|       from small pool |       0 B  |  496640 B  |  141505 KB |  141505 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|       from large pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |    2047 KB |  143552 KB |  143552 KB |\n",
      "|       from large pool |       0 B  |       0 KB |       0 KB |       0 KB |\n",
      "|       from small pool |       0 B  |    2047 KB |  143552 KB |  143552 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |      58    |    6530    |    6530    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |      58    |    6530    |    6530    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |      58    |    6530    |    6530    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |      58    |    6530    |    6530    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |      12    |    2979    |    2979    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |      12    |    2979    |    2979    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ran without profiler\n",
    "print(torch.cuda.memory_summary(cuda0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
