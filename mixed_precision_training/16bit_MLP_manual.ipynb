{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "import apex.fp16_utils as fp16\n",
    "\n",
    "import os\n",
    "import time, gc\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.moduleCodeProfiler import rankByCriteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 25 04:24:01 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 0000F9A8:00:00.0 Off |                  Off |\r\n",
      "| N/A   29C    P0    24W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "args = parser.parse_args('')\n",
    "\n",
    "args.data_dir = '~/datadrive'\n",
    "args.dataset_dir = 'toy_mlp_1'\n",
    "args.seed = 123\n",
    "args.batch_size = 1000\n",
    "# https://stackoverflow.com/questions/15753701/how-can-i-pass-a-list-as-a-command-line-argument-with-argparse\n",
    "args.hidden_layer_dims = [50, 50, 50, 50, 50, 50, 50]\n",
    "args.lr = 0.01\n",
    "args.epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 training indices [1603 8472 2213  498 1038 8399 3324 7535 1519 1959]\n",
      "X shape (9000, 10)\n",
      "y shape (9000,)\n"
     ]
    }
   ],
   "source": [
    "# construct and save toydataset\n",
    "\n",
    "m_train = 9000\n",
    "m_total = m_train\n",
    "\n",
    "X, y = make_classification(n_samples=m_total, n_features=10, n_informative=10, n_redundant=0, n_repeated=0, n_classes=5, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=args.seed)\n",
    "# y = np.expand_dims(y, -1)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "permutation = np.random.permutation(m_total)\n",
    "print('First 10 training indices', permutation[:10])\n",
    "print('X shape', X.shape)\n",
    "print('y shape', y.shape)\n",
    "\n",
    "train_indices = permutation[0:m_train]\n",
    "\n",
    "dataset_dir = 'toy_mlp_1'\n",
    "os.makedirs(os.path.join(args.data_dir, dataset_dir, 'train'), mode = 0o777, exist_ok = True) \n",
    "\n",
    "np.save(os.path.join(args.data_dir, dataset_dir, 'train', 'features.npy'), X[train_indices])\n",
    "np.save(os.path.join(args.data_dir, dataset_dir, 'train', 'labels.npy'), y[train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset(Dataset):\n",
    "    \"\"\"Toy dataset construction.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (string): Path to the directory with data files.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        # shape (m, nx)\n",
    "        self.X = np.load(os.path.join(data_dir, 'features.npy'))\n",
    "        # shape (m, ny=1)\n",
    "        self.y = np.load(os.path.join(data_dir, 'labels.npy'))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        else:\n",
    "            X = torch.from_numpy(self.X[idx, :]).type(torch.HalfTensor)\n",
    "            y = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "#             y = torch.from_numpy(self.y[idx, :]).type(torch.FloatTensor)\n",
    "            sample = {'X': X, 'y': y}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLazy(nn.Module):\n",
    "\n",
    "    def __init__(self, nx, hidden_layer_dims, ny):\n",
    "        super(MLPLazy, self).__init__()\n",
    "        self.hidden_layer_dims = hidden_layer_dims\n",
    "        \n",
    "        linear_layers = []\n",
    "        last_dim = nx\n",
    "        for next_dim in hidden_layer_dims:\n",
    "            linear_layer = nn.Linear(last_dim, next_dim)\n",
    "            linear_layers.append(linear_layer)\n",
    "            last_dim = next_dim\n",
    "        # should push to ModuleList so that params stay on cuda\n",
    "        self.linear_layers = nn.ModuleList(linear_layers)\n",
    "        self.scorer = nn.Linear(last_dim, ny)\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        X has shape (m, nx)\n",
    "        '''\n",
    "        last_X = X\n",
    "        for i, linear_layer in enumerate(self.linear_layers):\n",
    "            # shape (m, self.hidden_layer_dims[i])\n",
    "            last_X = linear_layer(last_X)\n",
    "            # shape (m, self.hidden_layer_dims[i])\n",
    "            last_X = torch.relu(last_X)\n",
    "        # shape (m, ny)\n",
    "        z = self.scorer(last_X)\n",
    "        # shape (m, ny)\n",
    "        a = torch.softmax(z, dim=1)\n",
    "        return z, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    global start_time\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "def end_timer():\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weights_precision(model):\n",
    "    '''check weight precisions for each layer of MLP'''\n",
    "    for i, layer in enumerate(model.linear_layers):\n",
    "        print(f'layer {i}, weight dtype {layer.weight.dtype}')\n",
    "        print(f'layer {i}, bias dtype {layer.bias.dtype}')\n",
    "    print(f'scorer weight dtype {model.scorer.weight.dtype}')\n",
    "    print(f'scorer bias dtype {model.scorer.bias.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_master(opt):\n",
    "    '''create a float32 master copy of float16 model weights in optimizer'''\n",
    "    model_pgs = [[param for param in pg['params'] if param.requires_grad] for pg in opt.param_groups]\n",
    "    master_pgs = [[param.clone().float().detach() for param in pg] for pg in model_pgs]\n",
    "    for pg in master_pgs:\n",
    "        for param in pg: param.requires_grad_(True)\n",
    "    return model_pgs, master_pgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_master_to_optimizer(opt, master_pgs):\n",
    "    '''\n",
    "        link master copy pgs to optimizer, \n",
    "        keeping other hparams such as lr, momentum dampening, weight_decay...'''\n",
    "    for opt_pg, master_pg in zip(opt.param_groups, master_pgs):\n",
    "        opt_pg['params'] = master_pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_master_grads(model_pgs, master_pgs, flat_master:bool=False):\n",
    "    '''copy float16 gradients from model to float32 gradients in master copy of weights'''\n",
    "    for (model_params,master_params) in zip(model_pgs,master_pgs):\n",
    "        fp16.model_grads_to_master_grads(model_params, master_params, flat_master=flat_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_model_params(model_pgs, master_pgs, flat_master:bool=False)->None:\n",
    "    '''copy master copy of updated weights in float32 to model weights in float 16'''\n",
    "    for (model_params,master_params) in zip(model_pgs,master_pgs):\n",
    "        fp16.master_params_to_model_params(model_params, master_params, flat_master=flat_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_down_master_grad(master_pgs, loss_scale):\n",
    "    '''\n",
    "    scale down all gradients for all master param groups\n",
    "    '''\n",
    "    for master_params in master_pgs:\n",
    "        for param in master_params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.div_(loss_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_memory_alloc():\n",
    "    devices_max_memory_alloc = {}\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        device = torch.device(f'cuda:{i}')\n",
    "        devices_max_memory_alloc[f'cuda:{i}'] = torch.cuda.max_memory_allocated(device) / 1e6\n",
    "        torch.cuda.reset_max_memory_allocated(device)\n",
    "    return devices_max_memory_alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overflow(loss, param_groups):\n",
    "    '''check if any loss or gradients in parameter groups overflow'''\n",
    "    loss_overflow = torch.isinf(loss)\n",
    "    grad_overflow = any([torch.any(torch.isinf(p.grad)).item() for pg in param_groups for p in pg])\n",
    "    return loss_overflow or grad_overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train(args, gpu=0, debug=False):\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    \n",
    "    ################################################################\n",
    "    # load datasets\n",
    "    training_set = ToyDataset(data_dir=os.path.join(args.data_dir, args.dataset_dir, 'train'))\n",
    "    training_generator = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                                        batch_size=args.batch_size, \n",
    "                                                        shuffle=True, \n",
    "                                                        num_workers=0, \n",
    "                                                        pin_memory=True)\n",
    "\n",
    "    nx = training_set.X.shape[1]\n",
    "    ny = max(training_set.y) + 1\n",
    "    ################################################################\n",
    "\n",
    "    # 1. Create model\n",
    "    model = MLPLazy(nx, args.hidden_layer_dims, ny)  # single\n",
    "    loss_criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model.to(device=gpu)    \n",
    "\n",
    "    # 2. initialize optimizer\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=args.lr)  # half\n",
    "    if debug:\n",
    "        print('\\nmodel weights at init')\n",
    "        check_weights_precision(model)\n",
    "\n",
    "    # 3. Cast model to float16\n",
    "    fp16.convert_network(model, torch.float16)\n",
    "#     model.half()\n",
    "    if debug:\n",
    "        print('\\nmodel weights after casting')\n",
    "        check_weights_precision(model)\n",
    "\n",
    "    # 4. Create a copy of this float16 model's weight in float32 as the master copy\n",
    "    model_pgs, master_pgs = get_master(opt)  # half, single\n",
    "\n",
    "    # 5. replace optimizer float16 weights with float32 master copy\n",
    "    push_master_to_optimizer(opt, master_pgs)  # opt single\n",
    "\n",
    "    def check_grad():\n",
    "        print('optimizer grad:\\n', opt.param_groups[0]['params'][0].grad)\n",
    "        print('master pg grad:\\n', master_pgs[0][0].grad)\n",
    "        print('model pg grad:\\n', model_pgs[0][0].grad)\n",
    "\n",
    "    def check_weights():\n",
    "        print('optimizer weights:\\n', opt.param_groups[0]['params'][0])\n",
    "        print('master pg weights:\\n', master_pgs[0][0])\n",
    "        print('model pg weights:\\n', model_pgs[0][0])\n",
    "\n",
    "    history = {\n",
    "        'epoch_train_losses': [], 'step_train_losses': [], 'max_memory_allocation':[], \n",
    "        'loss_scales':[], 'timing': defaultdict(int)\n",
    "    }\n",
    "    loss_scale = 50000\n",
    "    \n",
    "    loop_start_time = time.time()\n",
    "    \n",
    "    for e in range(5000):\n",
    "        start_timer()\n",
    "        model.train()\n",
    "        sum_batch_losses = torch.tensor([0.], dtype=torch.float, device=gpu)\n",
    "        all_batch_losses = []\n",
    "        batch_max_memory_alloc = []\n",
    "        loss_scales = []\n",
    "        history['timing']['epoch_setup'] += end_timer()\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        for batch_i, batch_data in enumerate(training_generator):\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            if debug: \n",
    "                print(f'\\nRunning batch_{batch_i}-----------------------------------------')\n",
    "\n",
    "            loss_scales.append(loss_scale)\n",
    "            \n",
    "            start_timer()\n",
    "            batch_max_memory_alloc.append(get_max_memory_alloc()['cuda:0'])\n",
    "            history['timing']['get_memory'] += end_timer()\n",
    "\n",
    "            # 6. model forward with float16 data\n",
    "            # NOTE: model zero grad, master last grad\n",
    "            start_timer()\n",
    "            batch_X = batch_data['X'].cuda(gpu, non_blocking=True) # half\n",
    "            batch_y = batch_data['y'].cuda(gpu, non_blocking=True) # long\n",
    "            history['timing']['data'] += end_timer()\n",
    "            \n",
    "            start_timer()\n",
    "            logits, activations = model(batch_X) # Half\n",
    "            history['timing']['forward'] += end_timer()\n",
    "\n",
    "            # 7. compute loss in float16\n",
    "            # NOTE: model zero grad, master last grad\n",
    "            start_timer()\n",
    "            loss = loss_criterion(logits, batch_y)  # half\n",
    "            history['timing']['loss'] += end_timer()\n",
    "            if debug:\n",
    "                print('\\nComputed loss')\n",
    "                check_grad()\n",
    "                check_weights()\n",
    "            # log the loss metric\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            start_timer()\n",
    "            sum_batch_losses += loss\n",
    "            all_batch_losses.append(loss)\n",
    "            history['timing']['append_losses'] += end_timer()\n",
    "            if debug:\n",
    "                print('all_batch_losses:', all_batch_losses)\n",
    "\n",
    "            # 8. scale up loss here\n",
    "            if debug:            \n",
    "                print('\\nloss scale in scale up:', loss_scale)\n",
    "                print('loss before scaling:', loss.item(), loss.dtype)\n",
    "            start_timer()\n",
    "            loss *= loss_scale\n",
    "            history['timing']['scale_up_loss'] += end_timer()\n",
    "            if debug:     \n",
    "                print('loss after scaling:', loss.item(), loss.dtype)\n",
    "\n",
    "            # 9. backprop to compute gradients\n",
    "            # NOTE: model new grad, master last grad\n",
    "            # NOTE: when we call backward, gradient accumulate on model gradient, not master gradient\n",
    "            start_timer()\n",
    "            loss.backward()  # half\n",
    "            history['timing']['backward'] += end_timer()\n",
    "            if debug:\n",
    "                print('\\nCalled backward to compute gradients')\n",
    "                check_grad()\n",
    "                check_weights()\n",
    "\n",
    "            # 10. check if gradient or loss overflow\n",
    "            start_timer()\n",
    "            if check_overflow(loss, model_pgs):\n",
    "                print('Overflow!')\n",
    "                # half the loss scale\n",
    "                loss_scale /= 2.\n",
    "                model.zero_grad()\n",
    "                continue\n",
    "            history['timing']['check_overflow'] += end_timer()\n",
    "                \n",
    "            # 11. copy float16 gradients from model to float32 gradients in master copy of weights\n",
    "            # NOTE: model new grad, master new grad\n",
    "            start_timer()\n",
    "            to_master_grads(model_pgs, master_pgs)\n",
    "            history['timing']['to_master_grads'] += end_timer()\n",
    "            if debug:\n",
    "                print('\\nCopied model grad to master grad')\n",
    "                check_grad()\n",
    "                check_weights()\n",
    "\n",
    "            # 12. scale down master copy gradients\n",
    "            if debug:    \n",
    "                print('loss scale in scale down:', loss_scale)\n",
    "            start_timer()\n",
    "            scale_down_master_grad(master_pgs, loss_scale)\n",
    "            history['timing']['scale_down_master'] += end_timer()\n",
    "            if debug:\n",
    "                print('\\nScaled down gradients in master copy')\n",
    "                check_grad()\n",
    "                check_weights()\n",
    "\n",
    "            # 13.optimizer step on master weights\n",
    "            start_timer()\n",
    "            opt.step()\n",
    "            history['timing']['opt_step'] += end_timer()\n",
    "            if debug:\n",
    "                print('\\nOptimizer stepped')\n",
    "                check_grad()\n",
    "                check_weights()\n",
    "\n",
    "            # 14.zero out gradients in model\n",
    "            start_timer()\n",
    "            model.zero_grad()\n",
    "            history['timing']['zero_grad'] += end_timer()\n",
    "            if debug:\n",
    "                print('\\nModel gradients zeroed out')\n",
    "                check_grad()\n",
    "                check_weights()\n",
    "\n",
    "            # 15.copy float32 master weights to float16 model weights\n",
    "            # NOTE: model zero grad, master new grad\n",
    "            start_timer()\n",
    "            to_model_params(model_pgs, master_pgs)\n",
    "            history['timing']['to_model_params'] += end_timer()\n",
    "            if debug:\n",
    "                print('\\nCopy master weights to model weight')\n",
    "                check_grad()\n",
    "                check_weights()\n",
    "\n",
    "            # 16.\n",
    "            # up the loss scale\n",
    "            loss_scale *= 1.0003466337\n",
    "\n",
    "            history['timing']['batch_time'] += time.time() - batch_start_time\n",
    "        \n",
    "        start_timer()\n",
    "        num_batches = batch_i + 1.\n",
    "        history['epoch_train_losses'].append(sum_batch_losses/num_batches)\n",
    "        history['step_train_losses'] += all_batch_losses\n",
    "        history['max_memory_allocation'] += batch_max_memory_alloc\n",
    "        history['loss_scales'] += loss_scales\n",
    "        history['timing']['append'] += end_timer()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        history['timing']['epoch_end_time'] += time.time() - epoch_start_time\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    history['timing']['loop_end_time'] += time.time() - loop_start_time\n",
    "        \n",
    "    start_timer()\n",
    "    itemize = lambda x: [tensor_val.item() for tensor_val in x]\n",
    "    history['epoch_train_losses'] = itemize(history['epoch_train_losses'])   \n",
    "    history['step_train_losses'] = itemize(history['step_train_losses'])   \n",
    "    history['timing']['itemize_losses'] += end_timer()\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.939019203186035\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPLazy(100, [5000, 5000, 5000, 5000, 5000, 5000, 5000], 1)\n",
    "torch.cuda.set_device('cuda:0')\n",
    "mlp.to(device='cuda:0') \n",
    "mlp.half()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn((500, 100), dtype=torch.float16, device='cuda:0')\n",
    "start_time = time.time()\n",
    "for i in range(5000):\n",
    "    y_hat, _ = mlp(X)\n",
    "    loss = torch.sum(10 - y_hat)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.056530475616455\n"
     ]
    }
   ],
   "source": [
    "mlp32 = MLPLazy(100, [5000, 5000, 5000, 5000, 5000, 5000, 5000], 1)\n",
    "torch.cuda.set_device('cuda:0')\n",
    "mlp32.to(device='cuda:0')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn((500, 100), device='cuda:0')\n",
    "start_time = time.time()\n",
    "for i in range(5000):\n",
    "    y_hat, _ = mlp32(X)\n",
    "    loss = torch.sum(10 - y_hat)\n",
    "torch.cuda.synchronize()\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.640761137008667\n",
      "52.30562925338745\n"
     ]
    }
   ],
   "source": [
    "# with sad k80 16-bit emulation rather than native 16bit!\n",
    "import torch\n",
    "import time\n",
    "X = torch.randn((2000,2000)).cuda()\n",
    "Y = torch.randn((2000,2000)).cuda()\n",
    "t0 = time.time()\n",
    "for i in range(5000):\n",
    "\tX@Y\n",
    "t1 = time.time()\n",
    "torch.cuda.synchronize()\n",
    "print(t1 - t0)\n",
    "X = torch.randn((2000,2000)).cuda().half()\n",
    "Y = torch.randn((2000,2000)).cuda().half()\n",
    "t0 = time.time()\n",
    "for i in range(5000):\n",
    "\tX@Y\n",
    "t1 = time.time()\n",
    "torch.cuda.synchronize()\n",
    "print(t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.22260594367981\n",
      "0.993229866027832\n"
     ]
    }
   ],
   "source": [
    "# with V100!\n",
    "import torch\n",
    "import time\n",
    "X = torch.randn((2000,2000)).cuda()\n",
    "Y = torch.randn((2000,2000)).cuda()\n",
    "t0 = time.time()\n",
    "for i in range(5000):\n",
    "\tX@Y\n",
    "t1 = time.time()\n",
    "torch.cuda.synchronize()\n",
    "print(t1 - t0)\n",
    "X = torch.randn((2000,2000)).cuda().half()\n",
    "Y = torch.randn((2000,2000)).cuda().half()\n",
    "t0 = time.time()\n",
    "for i in range(5000):\n",
    "\tX@Y\n",
    "t1 = time.time()\n",
    "torch.cuda.synchronize()\n",
    "print(t1 - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 25 02:41:25 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  On   | 0000DF45:00:00.0 Off |                    0 |\r\n",
      "| N/A   29C    P0    24W / 250W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/cuda/memory.py:234: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflow!\n",
      "Overflow!\n",
      "Overflow!\n",
      "Overflow!\n",
      "Overflow!\n",
      "Overflow!\n",
      "1227.2407965660095\n"
     ]
    }
   ],
   "source": [
    "all_start_time = time.time()\n",
    "history, model = main_train(args, debug=False)\n",
    "torch.cuda.synchronize()\n",
    "print(time.time() - all_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parameters\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/cuda/memory.py:234: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflow!\n"
     ]
    }
   ],
   "source": [
    "with profiler.profile(profile_memory=True, record_shapes=True, use_cuda=False, with_stack=True) as prof:\n",
    "    with profiler.record_function(\"forward\"):\n",
    "        history, model = main_train(args, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.611328125,\n",
       " 1.6201171875,\n",
       " 1.611328125,\n",
       " 1.6103515625,\n",
       " 1.6181640625,\n",
       " 1.6103515625,\n",
       " 1.6103515625,\n",
       " 1.6181640625,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.61328125,\n",
       " 1.6181640625,\n",
       " 1.607421875,\n",
       " 1.6103515625,\n",
       " 1.6142578125,\n",
       " 1.6142578125,\n",
       " 1.6171875,\n",
       " 1.6103515625,\n",
       " 1.615234375,\n",
       " 1.6123046875,\n",
       " 1.6171875,\n",
       " 1.615234375,\n",
       " 1.6103515625,\n",
       " 1.611328125,\n",
       " 1.61328125,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.6123046875,\n",
       " 1.6123046875,\n",
       " 1.6123046875,\n",
       " 1.6123046875,\n",
       " 1.61328125,\n",
       " 1.615234375,\n",
       " 1.61328125,\n",
       " 1.611328125,\n",
       " 1.6142578125,\n",
       " 1.611328125,\n",
       " 1.615234375,\n",
       " 1.6103515625,\n",
       " 1.6123046875,\n",
       " 1.607421875,\n",
       " 1.6123046875,\n",
       " 1.615234375,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.6142578125,\n",
       " 1.611328125,\n",
       " 1.61328125,\n",
       " 1.609375,\n",
       " 1.6083984375,\n",
       " 1.6083984375,\n",
       " 1.6142578125,\n",
       " 1.6162109375,\n",
       " 1.611328125,\n",
       " 1.6142578125,\n",
       " 1.6142578125,\n",
       " 1.6103515625,\n",
       " 1.607421875,\n",
       " 1.607421875,\n",
       " 1.61328125,\n",
       " 1.6123046875,\n",
       " 1.611328125,\n",
       " 1.609375,\n",
       " 1.61328125,\n",
       " 1.6103515625,\n",
       " 1.6123046875,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.61328125,\n",
       " 1.6083984375,\n",
       " 1.6162109375,\n",
       " 1.615234375,\n",
       " 1.6044921875,\n",
       " 1.615234375,\n",
       " 1.6123046875,\n",
       " 1.6123046875,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.611328125,\n",
       " 1.607421875,\n",
       " 1.61328125,\n",
       " 1.6103515625,\n",
       " 1.6103515625,\n",
       " 1.615234375,\n",
       " 1.6142578125,\n",
       " 1.6103515625,\n",
       " 1.607421875,\n",
       " 1.6103515625,\n",
       " 1.6064453125,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.61328125,\n",
       " 1.6103515625,\n",
       " 1.6142578125,\n",
       " 1.6064453125,\n",
       " 1.611328125,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.6123046875,\n",
       " 1.6103515625,\n",
       " 1.6083984375,\n",
       " 1.611328125,\n",
       " 1.6083984375,\n",
       " 1.61328125,\n",
       " 1.6083984375,\n",
       " 1.6083984375,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.6123046875,\n",
       " 1.609375,\n",
       " 1.61328125,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.607421875,\n",
       " 1.6103515625,\n",
       " 1.6103515625,\n",
       " 1.6103515625,\n",
       " 1.6064453125,\n",
       " 1.607421875,\n",
       " 1.6083984375,\n",
       " 1.609375,\n",
       " 1.61328125,\n",
       " 1.6142578125,\n",
       " 1.609375,\n",
       " 1.611328125,\n",
       " 1.611328125,\n",
       " 1.607421875,\n",
       " 1.611328125,\n",
       " 1.607421875,\n",
       " 1.6103515625,\n",
       " 1.6083984375,\n",
       " 1.607421875,\n",
       " 1.6123046875,\n",
       " 1.60546875,\n",
       " 1.609375,\n",
       " 1.6123046875,\n",
       " 1.6123046875,\n",
       " 1.6103515625,\n",
       " 1.607421875,\n",
       " 1.61328125,\n",
       " 1.607421875,\n",
       " 1.607421875,\n",
       " 1.6083984375,\n",
       " 1.61328125,\n",
       " 1.6123046875,\n",
       " 1.6162109375,\n",
       " 1.6083984375,\n",
       " 1.609375,\n",
       " 1.607421875,\n",
       " 1.603515625,\n",
       " 1.6044921875,\n",
       " 1.6083984375,\n",
       " 1.6123046875,\n",
       " 1.607421875,\n",
       " 1.6123046875,\n",
       " 1.609375,\n",
       " 1.6015625,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.607421875,\n",
       " 1.609375,\n",
       " 1.611328125,\n",
       " 1.6064453125,\n",
       " 1.6083984375,\n",
       " 1.6083984375,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.6083984375,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.6064453125,\n",
       " 1.6083984375,\n",
       " 1.607421875,\n",
       " 1.609375,\n",
       " 1.60546875,\n",
       " 1.611328125,\n",
       " 1.609375,\n",
       " 1.6064453125,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.607421875,\n",
       " 1.6083984375,\n",
       " 1.6103515625,\n",
       " 1.611328125,\n",
       " 1.6083984375,\n",
       " 1.6064453125,\n",
       " 1.607421875,\n",
       " 1.6064453125,\n",
       " 1.6103515625,\n",
       " 1.6064453125,\n",
       " 1.6083984375,\n",
       " 1.609375,\n",
       " 1.6083984375,\n",
       " 1.609375,\n",
       " 1.611328125,\n",
       " 1.6064453125,\n",
       " 1.6064453125,\n",
       " 1.6025390625,\n",
       " 1.6103515625,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.6064453125,\n",
       " 1.6103515625,\n",
       " 1.6064453125,\n",
       " 1.6083984375,\n",
       " 1.609375,\n",
       " 1.6064453125,\n",
       " 1.611328125,\n",
       " 1.6025390625,\n",
       " 1.609375,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.6103515625,\n",
       " 1.6064453125,\n",
       " 1.6064453125,\n",
       " 1.609375,\n",
       " 1.6103515625,\n",
       " 1.6064453125,\n",
       " 1.611328125,\n",
       " 1.60546875,\n",
       " 1.6083984375,\n",
       " 1.607421875,\n",
       " 1.6064453125,\n",
       " 1.60546875,\n",
       " 1.609375,\n",
       " 1.6083984375,\n",
       " 1.6103515625,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.609375,\n",
       " 1.6083984375,\n",
       " 1.6044921875,\n",
       " 1.6103515625,\n",
       " 1.607421875,\n",
       " 1.607421875,\n",
       " 1.6083984375,\n",
       " 1.6025390625,\n",
       " 1.607421875,\n",
       " 1.607421875,\n",
       " 1.609375,\n",
       " 1.60546875,\n",
       " 1.609375,\n",
       " 1.6083984375,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.609375,\n",
       " 1.609375,\n",
       " 1.6064453125,\n",
       " 1.609375,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.6064453125,\n",
       " 1.6064453125,\n",
       " 1.607421875,\n",
       " 1.607421875,\n",
       " 1.6103515625,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.609375,\n",
       " 1.607421875,\n",
       " 1.6044921875,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.6083984375,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.607421875,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.609375,\n",
       " 1.6064453125,\n",
       " 1.607421875,\n",
       " 1.607421875,\n",
       " 1.607421875,\n",
       " 1.6025390625,\n",
       " 1.6064453125,\n",
       " 1.6083984375,\n",
       " 1.6064453125,\n",
       " 1.6064453125,\n",
       " 1.60546875,\n",
       " 1.6083984375,\n",
       " 1.6103515625,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.6083984375,\n",
       " 1.6064453125,\n",
       " 1.609375,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.603515625,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.6083984375,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.609375,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.603515625,\n",
       " 1.6044921875,\n",
       " 1.6083984375,\n",
       " 1.6083984375,\n",
       " 1.6064453125,\n",
       " 1.603515625,\n",
       " 1.60546875,\n",
       " 1.609375,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.6083984375,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.6083984375,\n",
       " 1.6103515625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.611328125,\n",
       " 1.6044921875,\n",
       " 1.6044921875,\n",
       " 1.6064453125,\n",
       " 1.6064453125,\n",
       " 1.603515625,\n",
       " 1.6083984375,\n",
       " 1.6044921875,\n",
       " 1.6044921875,\n",
       " 1.603515625,\n",
       " 1.609375,\n",
       " 1.6083984375,\n",
       " 1.6044921875,\n",
       " 1.6044921875,\n",
       " 1.607421875,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.603515625,\n",
       " 1.6064453125,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.607421875,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.603515625,\n",
       " 1.6025390625,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.6044921875,\n",
       " 1.609375,\n",
       " 1.6044921875,\n",
       " 1.6064453125,\n",
       " 1.603515625,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.603515625,\n",
       " 1.6025390625,\n",
       " 1.607421875,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.6044921875,\n",
       " 1.6064453125,\n",
       " 1.6015625,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.6044921875,\n",
       " 1.603515625,\n",
       " 1.6064453125,\n",
       " 1.6025390625,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.603515625,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.603515625,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.6005859375,\n",
       " 1.6064453125,\n",
       " 1.60546875,\n",
       " 1.6044921875,\n",
       " 1.603515625,\n",
       " 1.6044921875,\n",
       " 1.6015625,\n",
       " 1.603515625,\n",
       " 1.6025390625,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.607421875,\n",
       " 1.6044921875,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.607421875,\n",
       " 1.6044921875,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.6064453125,\n",
       " 1.6015625,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.6064453125,\n",
       " 1.6015625,\n",
       " 1.60546875,\n",
       " 1.6025390625,\n",
       " 1.603515625,\n",
       " 1.60546875,\n",
       " 1.603515625,\n",
       " 1.6044921875,\n",
       " 1.6015625,\n",
       " 1.60546875,\n",
       " 1.6025390625,\n",
       " 1.6044921875,\n",
       " 1.603515625,\n",
       " 1.6064453125,\n",
       " 1.60546875,\n",
       " 1.60546875,\n",
       " 1.6015625,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.6044921875,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.603515625,\n",
       " 1.6044921875,\n",
       " 1.6025390625,\n",
       " 1.6025390625,\n",
       " 1.6044921875,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.6025390625,\n",
       " 1.603515625,\n",
       " 1.60546875,\n",
       " 1.603515625,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.6025390625,\n",
       " 1.60546875,\n",
       " 1.6015625,\n",
       " 1.603515625,\n",
       " 1.60546875,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6064453125,\n",
       " 1.6044921875,\n",
       " 1.6025390625,\n",
       " 1.6025390625,\n",
       " 1.6025390625,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.6015625,\n",
       " 1.6044921875,\n",
       " 1.6044921875,\n",
       " 1.6015625,\n",
       " 1.6064453125,\n",
       " 1.60546875,\n",
       " 1.6025390625,\n",
       " 1.6015625,\n",
       " 1.599609375,\n",
       " 1.603515625,\n",
       " 1.599609375,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.6005859375,\n",
       " 1.6025390625,\n",
       " 1.6044921875,\n",
       " 1.60546875,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.6044921875,\n",
       " 1.599609375,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6044921875,\n",
       " 1.6044921875,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.6025390625,\n",
       " 1.599609375,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.6015625,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.603515625,\n",
       " 1.60546875,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.599609375,\n",
       " 1.6025390625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6044921875,\n",
       " 1.599609375,\n",
       " 1.6005859375,\n",
       " 1.6025390625,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.6044921875,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.603515625,\n",
       " 1.5986328125,\n",
       " 1.603515625,\n",
       " 1.6025390625,\n",
       " 1.603515625,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.603515625,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.603515625,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.599609375,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.599609375,\n",
       " 1.60546875,\n",
       " 1.6005859375,\n",
       " 1.603515625,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.6015625,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.599609375,\n",
       " 1.6044921875,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.599609375,\n",
       " 1.6015625,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6015625,\n",
       " 1.6005859375,\n",
       " 1.5986328125,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.6005859375,\n",
       " 1.5986328125,\n",
       " 1.6015625,\n",
       " 1.6005859375,\n",
       " 1.6025390625,\n",
       " 1.603515625,\n",
       " 1.6005859375,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.603515625,\n",
       " 1.5986328125,\n",
       " 1.6015625,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.5986328125,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.5966796875,\n",
       " 1.6005859375,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.6015625,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.6025390625,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.6005859375,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.6005859375,\n",
       " 1.59765625,\n",
       " 1.6005859375,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.5966796875,\n",
       " 1.599609375,\n",
       " 1.6005859375,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.6015625,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.6005859375,\n",
       " 1.59765625,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.6005859375,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.59765625,\n",
       " 1.6005859375,\n",
       " 1.5966796875,\n",
       " 1.599609375,\n",
       " 1.59765625,\n",
       " 1.5986328125,\n",
       " 1.6015625,\n",
       " 1.5966796875,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.6005859375,\n",
       " 1.59765625,\n",
       " 1.59765625,\n",
       " 1.599609375,\n",
       " 1.6005859375,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.6005859375,\n",
       " 1.5966796875,\n",
       " 1.59765625,\n",
       " 1.5986328125,\n",
       " 1.5966796875,\n",
       " 1.5986328125,\n",
       " 1.6005859375,\n",
       " 1.6015625,\n",
       " 1.595703125,\n",
       " 1.599609375,\n",
       " 1.5966796875,\n",
       " 1.59765625,\n",
       " 1.6005859375,\n",
       " 1.599609375,\n",
       " 1.595703125,\n",
       " 1.59765625,\n",
       " 1.59765625,\n",
       " 1.5966796875,\n",
       " 1.6005859375,\n",
       " 1.5966796875,\n",
       " 1.5986328125,\n",
       " 1.59765625,\n",
       " 1.59765625,\n",
       " 1.59765625,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.5966796875,\n",
       " 1.599609375,\n",
       " 1.5947265625,\n",
       " 1.5986328125,\n",
       " 1.5966796875,\n",
       " 1.6005859375,\n",
       " 1.595703125,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.5966796875,\n",
       " 1.595703125,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.599609375,\n",
       " 1.59765625,\n",
       " 1.595703125,\n",
       " 1.59765625,\n",
       " 1.5966796875,\n",
       " 1.5986328125,\n",
       " 1.5947265625,\n",
       " 1.595703125,\n",
       " 1.5966796875,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.5986328125,\n",
       " 1.5947265625,\n",
       " 1.5966796875,\n",
       " 1.5986328125,\n",
       " 1.599609375,\n",
       " 1.5986328125,\n",
       " 1.595703125,\n",
       " 1.5986328125,\n",
       " 1.5966796875,\n",
       " 1.5947265625,\n",
       " 1.5966796875,\n",
       " 1.5986328125,\n",
       " 1.595703125,\n",
       " 1.5966796875,\n",
       " 1.5966796875,\n",
       " 1.595703125,\n",
       " 1.59765625,\n",
       " 1.595703125,\n",
       " 1.59765625,\n",
       " 1.5966796875,\n",
       " 1.599609375,\n",
       " 1.59765625,\n",
       " 1.595703125,\n",
       " 1.595703125,\n",
       " 1.595703125,\n",
       " 1.5966796875,\n",
       " 1.5947265625,\n",
       " 1.59765625,\n",
       " 1.59375,\n",
       " 1.595703125,\n",
       " 1.59765625,\n",
       " 1.5966796875,\n",
       " 1.59765625,\n",
       " 1.5947265625,\n",
       " 1.59765625,\n",
       " 1.59765625,\n",
       " 1.5966796875,\n",
       " 1.595703125,\n",
       " 1.5927734375,\n",
       " 1.599609375,\n",
       " 1.5966796875,\n",
       " 1.595703125,\n",
       " 1.5966796875,\n",
       " 1.5966796875,\n",
       " 1.595703125,\n",
       " 1.595703125,\n",
       " 1.595703125,\n",
       " 1.595703125,\n",
       " 1.5947265625,\n",
       " 1.5966796875,\n",
       " 1.59765625,\n",
       " 1.595703125,\n",
       " 1.5947265625,\n",
       " 1.5966796875,\n",
       " 1.59375,\n",
       " 1.59375,\n",
       " 1.5947265625,\n",
       " 1.5986328125,\n",
       " 1.595703125,\n",
       " 1.5986328125,\n",
       " 1.595703125,\n",
       " 1.5927734375,\n",
       " 1.5947265625,\n",
       " 1.5947265625,\n",
       " 1.5927734375,\n",
       " 1.59375,\n",
       " 1.5966796875,\n",
       " 1.5927734375,\n",
       " 1.595703125,\n",
       " 1.595703125,\n",
       " 1.5966796875,\n",
       " 1.5986328125,\n",
       " 1.5947265625,\n",
       " 1.59375,\n",
       " 1.5947265625,\n",
       " 1.595703125,\n",
       " 1.5947265625,\n",
       " 1.5947265625,\n",
       " 1.595703125,\n",
       " 1.5947265625,\n",
       " 1.5927734375,\n",
       " 1.5966796875,\n",
       " 1.5947265625,\n",
       " 1.5986328125,\n",
       " 1.59375,\n",
       " 1.5927734375,\n",
       " 1.5927734375,\n",
       " 1.59375,\n",
       " 1.59375,\n",
       " 1.595703125,\n",
       " 1.5966796875,\n",
       " 1.591796875,\n",
       " 1.5947265625,\n",
       " 1.591796875,\n",
       " 1.5927734375,\n",
       " 1.595703125,\n",
       " 1.59375,\n",
       " 1.5966796875,\n",
       " 1.59765625,\n",
       " 1.59375,\n",
       " 1.5927734375,\n",
       " 1.5966796875,\n",
       " 1.5947265625,\n",
       " 1.59375,\n",
       " 1.5947265625,\n",
       " 1.5966796875,\n",
       " 1.5947265625,\n",
       " 1.591796875,\n",
       " 1.5908203125,\n",
       " 1.59375,\n",
       " 1.595703125,\n",
       " 1.5966796875,\n",
       " 1.59375,\n",
       " 1.59375,\n",
       " 1.5908203125,\n",
       " 1.5966796875,\n",
       " 1.5927734375,\n",
       " 1.5908203125,\n",
       " 1.5927734375,\n",
       " 1.59375,\n",
       " 1.59375,\n",
       " 1.59375,\n",
       " 1.5947265625,\n",
       " 1.5908203125,\n",
       " 1.591796875,\n",
       " 1.59375,\n",
       " 1.59765625,\n",
       " 1.59375,\n",
       " 1.5927734375,\n",
       " 1.5927734375,\n",
       " 1.5947265625,\n",
       " 1.5966796875,\n",
       " 1.5908203125,\n",
       " 1.591796875,\n",
       " 1.5947265625,\n",
       " 1.591796875,\n",
       " 1.59375,\n",
       " 1.58984375,\n",
       " 1.59375,\n",
       " 1.5908203125,\n",
       " 1.5947265625,\n",
       " 1.59375,\n",
       " 1.5927734375,\n",
       " 1.59375,\n",
       " 1.5947265625,\n",
       " 1.5888671875,\n",
       " 1.5908203125,\n",
       " 1.5947265625,\n",
       " 1.59375,\n",
       " 1.58984375,\n",
       " 1.5947265625,\n",
       " 1.5947265625,\n",
       " 1.58984375,\n",
       " 1.5966796875,\n",
       " 1.591796875,\n",
       " 1.59375,\n",
       " 1.5947265625,\n",
       " 1.5888671875,\n",
       " 1.5927734375,\n",
       " 1.5947265625,\n",
       " 1.5908203125,\n",
       " 1.591796875,\n",
       " 1.5908203125,\n",
       " 1.5927734375,\n",
       " 1.5888671875,\n",
       " 1.5927734375,\n",
       " 1.5888671875,\n",
       " 1.595703125,\n",
       " 1.59375,\n",
       " 1.59375,\n",
       " 1.5927734375,\n",
       " 1.5869140625,\n",
       " 1.5947265625,\n",
       " 1.591796875,\n",
       " 1.587890625,\n",
       " 1.5927734375,\n",
       " 1.59375,\n",
       " 1.58984375,\n",
       " 1.591796875,\n",
       " 1.58984375,\n",
       " 1.5927734375,\n",
       " 1.5927734375,\n",
       " 1.587890625,\n",
       " 1.587890625,\n",
       " 1.591796875,\n",
       " 1.591796875,\n",
       " 1.5888671875,\n",
       " 1.5966796875,\n",
       " 1.5947265625,\n",
       " 1.58984375,\n",
       " 1.58984375,\n",
       " 1.595703125,\n",
       " 1.58984375,\n",
       " 1.5908203125,\n",
       " 1.58984375,\n",
       " 1.58984375,\n",
       " 1.58984375,\n",
       " 1.591796875,\n",
       " 1.5908203125,\n",
       " 1.5927734375,\n",
       " 1.5888671875,\n",
       " 1.5908203125,\n",
       " 1.5908203125,\n",
       " 1.5908203125,\n",
       " 1.5888671875,\n",
       " 1.591796875,\n",
       " 1.587890625,\n",
       " 1.5927734375,\n",
       " 1.587890625,\n",
       " 1.5908203125,\n",
       " 1.5947265625,\n",
       " 1.587890625,\n",
       " 1.5888671875,\n",
       " 1.5888671875,\n",
       " 1.59375,\n",
       " 1.5908203125,\n",
       " 1.587890625,\n",
       " 1.5849609375,\n",
       " 1.5888671875,\n",
       " 1.591796875,\n",
       " 1.587890625,\n",
       " 1.5947265625,\n",
       " 1.587890625,\n",
       " 1.587890625,\n",
       " 1.5908203125,\n",
       " 1.5927734375,\n",
       " 1.591796875,\n",
       " 1.587890625,\n",
       " 1.5908203125,\n",
       " 1.5888671875,\n",
       " 1.5888671875,\n",
       " 1.58984375,\n",
       " 1.5888671875,\n",
       " 1.58984375,\n",
       " 1.5888671875,\n",
       " 1.587890625,\n",
       " 1.5869140625,\n",
       " 1.591796875,\n",
       " 1.5869140625,\n",
       " 1.5888671875,\n",
       " 1.591796875,\n",
       " 1.58984375,\n",
       " 1.5908203125,\n",
       " 1.5869140625,\n",
       " 1.58984375,\n",
       " 1.5888671875,\n",
       " 1.5859375,\n",
       " 1.583984375,\n",
       " 1.5859375,\n",
       " 1.58984375,\n",
       " 1.58984375,\n",
       " 1.5927734375,\n",
       " 1.591796875,\n",
       " 1.5859375,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ran without profiler\n",
    "history['step_train_losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '16bit - Manual')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start at 50000\n",
    "plt.plot(np.arange(len(history['step_train_losses'])), np.array(history['step_train_losses']))\n",
    "plt.title('16bit - Manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '16bit - Manual')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start at 50000\n",
    "plt.plot(np.arange(len(history['epoch_train_losses'])), np.array(history['epoch_train_losses']))\n",
    "plt.title('16bit - Manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '16bit - Manual')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAffklEQVR4nO3deXBV55nn8e+D2PcdrQhs8MKiBWSME8exHS/sGO9xEiepZGgn4+7JTKW6naSrp3uS6k73TM10utppD5N2JZnuHieOMbsBO4njJG3HiEVCEhhjvGhHbGIzQsszf9wjca98gYuRdO+5+n2qVNzznlf3vvct+NXhPec8x9wdEREJvwHJHoCIiPQMBbqISJpQoIuIpAkFuohImlCgi4ikCQW6iEiaUKBLKJjZj83se5fYf9rMrunLMSWTmd1uZjXJHoekFgW69Bkze9LMSs2sxcx+HGf/cDP7oZkdMbNmM3st0fd295Hufih4n0uGf4JjfdXM3MwKu7WvC9pvv5r3F+kNCnTpS3XA94BnL7J/DTAeuDH48z/30bgu5gDweOeGmU0AFgJNSRuRyCUo0KXPuPtad18HHO2+z8yuB1YAq929yd3b3X1nt24TzexlMztlZr8xs/yo33czm2Fmq4HPAX8aLMNsvIoh/yvwiJllBNufBV4Ezkd97gIze93MTphZvZn9o5kN7jauJ8zsbTM7bmZPm5kF+/7SzP4lqu+0oP/AYPvLZrYv+L6HzOyPruK7SD+gQJdUcTPwPvBXwZLLXjN7oFufzwHfBSYCe4gEbgx3XxO0/12wDLP8KsZUB1QB9wTbjwM/7danncj/JCYCtwCfAb7erc8y4CagEHgYuDfBzz8c/O5o4MvA/zKzeVf2FaQ/UaBLqsgF5gDNQDbwJPATM7sxqs9md3/N3VuA7wC3mFleL4/rp8Djwf8gxrr769E73X2nu7/h7m3u/h7wv4FPd3uP77v7CXf/APg1UJTIB7v7Znd/xyN+A2wHPnWV30fSmAJdUsWHQCvwPXc/HwTYr7lwdAxQ3fnC3U8Dx4iE/xUxs28HyzGnzeyZy3RfC9wJ/DHwf+O813VmtsnMGszsJPDXRI7WozVEvT4LjExwnIvN7A0zO2ZmJ4Alcd5bpIsCXVJFeQJ9uo7GzWwkkROndXH6XbKEqLv/dbAcM9Ldn7hM37PAS8DXiBPowD8B+4GZ7j4a+DZgl/wWF5wBhkdtZ3a+MLMhwAvA/wCmuPtYYMsVvLf0Qwp06TNmNtDMhgIZQIaZDe08AQi8BnwAfCvo90ngdmBb1FssMbNbg5OO3wX+4O7VfFQj0JPXpH8b+HSwpNLdKOAkcNrMbiAS/InaA9xmZlPNbAzwrah9g4EhRK6oaTOzxcT+b0XkIxTo0pf+nMjSylPA54PXfw7g7q3ASiLLCs3A/wEed/f9Ub//b8B/JbLUMp/ISdJ4/hmYFVx5su5qB+3ude7+u4vs/ibwGHAqGPPPruB9Xw76lwM7gU1R+04BfwL8HDgefMaGjzN+6T9MD7gQEUkPOkIXEUkTCnQRkTShQBcRSRMKdBGRNDHw8l16x8SJE33atGnJ+ngRkVDauXPnEXefFG9f0gJ92rRplJaWJuvjRURCyczev9g+LbmIiKQJBbqISJpQoIuIpAkFuohImlCgi4ikCQW6iEiaUKCLiKSJpF2HLiLSn7g7rx86Sul7xynKG8tt18W9N+iqKNBFRHqJu/PqgSY2l9fz0t56zpxvB+Brt1+rQBcRSXXtHc4r+xrZXF7PtsoGWto6ALgxazRL52Zy/7xcsscO65XPVqCLiFyl1vYOXqpoYEt5Pa/sa6StI/LgoILcMSwryGJVcS6TRg3p9XEo0EVEPoaWtnY2ltWzubyOX7/V1NU+b+pYVhRmc19xDmOHD+7TMSnQRUQSdPZ8G+v31LGpvI7fHzza1b7wmvEsL8xmZVEOI4ckL1YV6CIil3DyXCvrdteysayOHe8d72q/7bpJLCvIYkVhNkMHZSRxhBckFOhmtgj4AZAB/Mjdv99t/+3AeuDdoGmtu/+3nhumiEjfOXbmPGt31bCxvJ6y6hMADDC468YpLC/MYvGcLAYPTL3beC4b6GaWATwN3A3UADvMbIO7V3Xr+lt3X9YLYxQR6XWNJ8+xdlfkSLyq/iQAgwcOYOncLJYVZHH3rCkMzEi9EI+WyBH6AuCgux8CMLPngJVA90AXEQmV6mNneWFXDVv21nOg8TQAwwdncH9xDksLsrjj+skMGGBJHmXiEgn0HKA6arsGuDlOv1vMrAyoA77p7pXdO5jZamA1wNSpU698tCIiV+ng4dOs3VXD1ooGDh05A8DooQN59KY8lhVk88kZEzALT4hHSyTQ430z77a9C8h399NmtgRYB8z8yC+5rwHWAJSUlHR/DxGRXlFVd5K1u2rYVtVA9bEPAZgwYjCP35LP8sJsSvLHhTbEoyUS6DVAXtR2LpGj8C7ufjLq9RYz+6GZTXT3Iz0zTBGRxLk7e6pP8OLuWrZXNtJw8hwAU0YP4au3TmdFUTYFuWOTO8hekEig7wBmmtl0oBZ4FHgsuoOZZQKN7u5mtoBIFcejH3knEZFe4u784d1jrNtdy/aqRo6dOQ9A7rhhfP32a1lZlMP1maOSPMreddlAd/c2M3sS2EbkssVn3b3SzJ4I9j8DPAh8zczagA+BR91dSyoi0qvaO5zfHzzCi7treaWqkVMtbQBcM3EEn1+Yz/3FOUybOCLJo+w7lqzcLSkp8dLS0qR8toiEV1t7B79+q4l1u2t5ZV9jV/GrGzJHsXRuFg/M773iV6nAzHa6e0m8fbpTVERS3vm2DrZXNbBhTx2v7GskqH1FYe4YFs3J4qGSXCaO7P3iV6lOgS4iKelcaztb9tazsSy2+NVN08Zx7+xMHr4pj9FDByVxhKlHgS4iKeN0Sxsby+rYsree37594SK5W2dM5J7ZU3hofh7DBqdG3ZRUpEAXkaRqPtvKuj21vFRRzxuHjnW133H9JBbNyeS+4hyGDFSIJ0KBLiJ97sjpFtbuqmF7ZSOl71+oYLhodiaL5mSyvDCbjBDdcp8qFOgi0ifqmz/khZ01bK9qpLymuat9RWE2i+Zksmh2ZqjqpqQiBbqI9JrqY2d5vrSa7VWN7G84BcDgjAE8MC+XpQWZ3HH95LS45T5VKNBFpEcdajrNz0qrebmqkUNNkeJXI4cM5LML8lhekM0t14a3+FWqU6CLyFXb33CSn+2oZntlI7UnIsWvxo8YzBcW5nNfcTbz88cneYT9gwJdRD6WsuoTPL+zmm2VjTSdagEgc/RQvvzJaTwwL5c5OWOSPML+R4EuIgl7891jvLCzhq2VDTR/2ApA/oTh/IdPTeeRm/KYMTm9i1+lOgW6iFyUu/Pbt49ErhPf28CHre0AzJw8ks8vnMrDJXnkT+g/xa9SnQJdRGJ0dDgv72tky956NpXX0x4UTpmdPZp7ZmXy8E25ZI1J3+JXYaZAFxHa2jvYUtHA1op6tuxt6GovnjqWe2Zl8uD8XCaNUvGrVKdAF+mnzrW2s6m8nq0VDbyyr7GrfeE147l7ViYPzMth7PDBSRyhXCkFukg/cqalLfJYtqpGXjtwoYLhp2ZO5N7ZmawsymaUKhiGlgJdJM01f9ga3HLfEFP86s4bJkfqphRkq4JhmlCgi6ShY2fO8/PSarZVNrD7gxNd7ffMmsLSgiwWz8li8MAByRug9AoFukiaaGg+x/Ol1WyraqCi9iQAAwcYS+dmsaIom8/cMJmBGQrxdKZAFwmxzuJXWysbONB4GoDhgzNYWZTN/fNyuXXGRJWh7UcU6CIhc/DwKdbuqmXz3nreP3oWgDHDBvHg/FwenJ/LgmnjVYa2n1Kgi4RARW0z6/fUsqm8nvrmcwBMGjWEx26eykPzcynKG6sKhqJAF0lVO98/zsayOjaW1XH0zHkAcscN40ufmMZDJbnMyhqtEJcYCnSRFOHuvH7oKJvK69lUVsfJc20AXDNxBA+W5PLQ/FwVv5JLUqCLJJG78+pbTV11UzqLX10/ZRRf+sQUHpifq+JXkjAFukgf6+hwtldFil9trWzgfFsHAHNyRrNodib3z8sle6yKX8mVU6CL9IG29g42763npb0NbK9qIChgSFHeWJbMzWRVsYpfydVToIv0kvNtHazfU8tLFQ38av/hrvaS/HEsL8xmZVG2il9Jj1Kgi/SgD8+388KuGrZWNPC7g0e62m+5ZgLLC7NZXpil4lfSaxIKdDNbBPwAyAB+5O7fv0i/m4A3gEfc/Rc9NkqRFHbqXCtrd9WyqbyOHe8d72q/7bpJrCjMZuncLBW/kj5x2UA3swzgaeBuoAbYYWYb3L0qTr+/Bbb1xkBFUsmxM+dZu6uGjWV1lNU0AzDA4K4bp7CiKJtFszNV/Er6XCJH6AuAg+5+CMDMngNWAlXd+v0x8AJwU4+OUCRFNDSfY+3uGjaW1bOvPlL8asjAASydm8XywizuunGKil9JUiUS6DlAddR2DXBzdAczywFWAXdyiUA3s9XAaoCpU6de6VhF+twHR8/y4u5aNpbXcfBwpPjVyCEDub84h2WFWdx+3WTVTZGUkUigx/vb6t22/x74M3dvv9StyO6+BlgDUFJS0v09RFLC242nWLenls3l9bwXFL8aO3wQj5TksaIom09cO0G33EtKSiTQa4C8qO1coK5bnxLgueAv+URgiZm1ufu6nhikSG+rqG1m3e7IJYa1Jz4EIsWvHr8lnxWF2czPH6cQl5SXSKDvAGaa2XSgFngUeCy6g7tP73xtZj8GNinMJZW5O7s+OMH6PbVsq2yg8WQLANljhvLVW6ezsiiHubljkjxKkStz2UB39zYze5LI1SsZwLPuXmlmTwT7n+nlMYr0iM7iVxvL6thW2cixoIJh3vhhfP32a1lZlMP1mSp+JeGV0HXo7r4F2NKtLW6Qu/uXrn5YIj2jo8P57cEjrN9dy8v7GjnVWcFw0gi+sDCfVcU5TJuo4leSHnSnqKSdtvYOfrX/MOv31PHL/Y2ca40Uv7ohcxTLC7NZVZyj4leSlhTokhbOt3WwvaohEuL7GruKXxXkjmFZQRb3z8tl4kgVv5L0pkCX0DrX2s7m8no2ltfx6ltNXe0l+eNYMjeLB0tyGa26KdKPKNAlVE63tLGprI6N5XX8/uDRrvZPzpjAotmZPFSSx9BBqpsi/ZMCXVJe89nWyI0+e+t5891jXe13XD+JxXOyuK84R3VTRFCgS4pqOtUS3OhTz64PTnS13zt7CovnZLGsIEt1U0S6UaBLyqhv/pC1u2rZWtHA3tpIBcOMAcaKwmwWzclk0exM1U0RuQQFuiTVB0fP8otdNWyvbGB/wykgUsHwwfm5LJmbyR3XT9Yt9yIJUqBLn3un6TQ/L63m5apGDjWdAWDUkIF8dsFUlhVkqfiVyMekQJc+sb/hJD/bEQnxmuOR4lfjRwzmi7fks6Iom/n545M8QpHwU6BLrymvOcHPS6vZXtnI4VOR4leZo4fylVuns6o4hzk5Kn4l0pMU6NJj3J0d7x3nFzur2V7VyImzrQDkTxjOH912DQ/Oz2XmFBW/EuktCnS5Kh0dzu8OHuHF3ZEytGfPtwMwY/JIPn9zPg+X5DF1wvAkj1Kkf1CgyxVr73Be2dfIxrI6tlY00BYUTpmdPZp7ZmXyyE15ZI4ZmuRRivQ/CnRJyPm2DrZWNrClvJ6tlQ1d7cVTx3LPrEweKlHxK5FkU6DLRZ1rbQ8eBtHAK/sOd7UvvGY8d8/K5MF5uYwZruJXIqlCgS4xTre0sX5PLdsrG/nNgQsVDD81cyL3zM5kVXEOI4for41IKtK/TKH5bCsv7Krh5apGXj90oYLhZ26YzL1zMllRmK0KhiIhoEDvp46cbuEXOyO33EcXv1o0O5PFczNZPCdLFQxFQkaB3o80NJ+L3OhT1UBF7UkgUvxqeWE2S+dmcfesKWSo+JVIaCnQ01z1sbP8bEckxA80ngZg2KAMVhXncF9xDp+aMVEVDEXShAI9DR08fIrnd9awtaKB94+eBWD00IE8ND+XB+fnsmD6eBW/EklDCvQ0UVHbzIu7a3lpbz11zecAmDhyCI/dPJWHS/Ioyhub3AGKSK9ToIfYzvePs2FPLZvK6zl65jwAOWOH8aVPTOORm/K4MWt0kkcoIn1JgR4i7s7rh46ysayeTWV1nGppA+CaiSN4cH4uD5XkMWPyyCSPUkSSRYGe4tydV99qYsveejaU1dHS1gHADZmjuGfWFB6Yn0v+hBFJHqWIpAIFegrq6HC2VzXwUkUDm8vru4pfzc0Z0xXi2WOHJXmUIpJqFOgpoq29g81769laEQnyTvOmjuXe2ZncPy+XSaNU/EpELk6BnkTn2zpYtyfylPtf7b9Q/GrBtPEsmZvJyqIcxo0YnMQRikiYKND72LnWdp7fWcO2igZ+d/BIV/snrp3AsoJslhdmMWqoKhiKyJVLKNDNbBHwAyAD+JG7f7/b/pXAd4EOoA34hrv/rofHGlqnzrXyfGnkRp833zvW1f7p6yaxojCbJXOzGDZYxa9E5OpcNtDNLAN4GrgbqAF2mNkGd6+K6vZLYIO7u5kVAD8HbuiNAYfF0dMtvLCrhs17GyirPgHAAIO7bpzCyqJs7p2dqeJXItKjEjlCXwAcdPdDAGb2HLAS6Ap0dz8d1X8E4D05yLBoaD7HC7tq2FRez776SPGrIQMHsGRuJvcV5XDnDZMZmKEQF5HekUig5wDVUds1wM3dO5nZKuBvgMnA0nhvZGargdUAU6dOvdKxpqT3j57hxd21bCyr452mMwCMHDKQVcU5rCjK5raZk1TBUET6RCKBHi+NPnIE7u4vAi+a2W1E1tPvitNnDbAGoKSkJLRH8QcaT7F+Ty0by+r54Fik+NW44YN4pCSPlcXZ3HLNBBW/EpE+l0ig1wB5Udu5QN3FOrv7a2Z2rZlNdPcjF+sXNhW1zazfU8vm8gvFr6aMHsIXFuZzX3E286aOU4iLSFIlEug7gJlmNh2oBR4FHovuYGYzgHeCk6LzgMHA0Y+8U4i4O7s+OM6GPXVsqWig6VQLECl+9ZVbp7OqOIc5OWOSPEoRkQsuG+ju3mZmTwLbiFy2+Ky7V5rZE8H+Z4AHgMfNrBX4EHjE3UO3pOLuvP7OUTaW17G1ooHjZ1sByJ8wnK/ffi33Fedw3ZRRSR6liEh8lqzcLSkp8dLS0qR8drSODuc3B5rYWFbHy1WNXRUMZ0weybKCLFYV56j4lYikDDPb6e4l8fb1yztF29o7eGXfYTaW1/HLfY2ca71QwXBFUTarinPIGqPiVyISLv0m0M+3dbC1soGNZXX8av9h2oMKhgW5Y1hRGAnxCSNV/EpEwiutA/1cazubyuvZWFbHbw40dbWX5I9jWUEW98/PZbTqpohImki7QD/d0sbGsjo27Knj9UMXLrT55IwJLJkbWRMfPjjtvraISHoEevPZVtbtqWVTeR073jve1X7H9ZNYPDeLlUXZDBmo4lcikt5CG+hNp1pYHzwgeU9U8at7Z09hydwsls7NUt0UEelXQhfo7R3Ol3+8g9eCNfFBGcbywmyWzMnkntmZqpsiIv1W6AL9yOkWXjvQxIQRg/nvDxVwx/WTdcu9iAghDPTmDyN3b/7litncecOUJI9GRCR1hG6RuSW4CWjYIJ3kFBGJFrpAFxGR+EIX6N4/H4YkInJZoQv0TjoPKiISK7SBLiIisUIX6OGrsi4i0jdCF+idtOQiIhIrtIEuIiKxQhfoWnEREYkvdIHeydCai4hItNAGuoiIxApdoCfrodYiIqkudIHeRSsuIiIxQhfoOj4XEYkvdIHeSQfoIiKxQhvoIiISK3SBrnOiIiLxhS7QO+mxcyIisUIb6CIiEiuEga41FxGReEIY6BFacBERiZVQoJvZIjN7y8wOmtlTcfZ/zszKg59/N7PCnh+qiIhcymUD3cwygKeBxcAs4LNmNqtbt3eBT7t7AfBdYE1PD7STrnIREYkvkSP0BcBBdz/k7ueB54CV0R3c/d/d/Xiw+QaQ27PD/Chd5CIiEiuRQM8BqqO2a4K2i/kK8FK8HWa22sxKzay0qakp8VGKiMhlJRLo8Y6F4y58mNkdRAL9z+Ltd/c17l7i7iWTJk1KfJSX+2AREWFgAn1qgLyo7VygrnsnMysAfgQsdvejPTO8i9MDLkREYiVyhL4DmGlm081sMPAosCG6g5lNBdYCX3D3Az0/zAt0UlREJL7LHqG7e5uZPQlsAzKAZ9290syeCPY/A/wFMAH4YXBLfpu7l/TesHVSVESku0SWXHD3LcCWbm3PRL3+KvDVnh2aiIhcidDdKapH0ImIxBe6QO+kFRcRkVihDXQREYkVukDXgouISHyhC/QuWnMREYkR3kAXEZEYoQt0XeQiIhJf6AK9k279FxGJFdpAFxGRWKELdNd1LiIicYUu0DuplouISKzwBboO0EVE4gpfoAd0gC4iEiu0gS4iIrFCF+hacRERiS90gd7JdFZURCRGaANdRERihS7Qdeu/iEh8oQv0TlpxERGJFdpAFxGRWKELdN36LyISX+gCvZNWXEREYoUu0HVSVEQkvtAFuoiIxBfaQNdVLiIisUIX6FpxERGJL3SBfoEO0UVEooU40EVEJFroAt11mYuISFwJBbqZLTKzt8zsoJk9FWf/DWb2upm1mNk3e36Y8cbUF58iIhIeAy/XwcwygKeBu4EaYIeZbXD3qqhux4A/Ae7rjUGKiMjlJXKEvgA46O6H3P088BywMrqDux929x1Aay+MMYYWXERE4ksk0HOA6qjtmqDtipnZajMrNbPSpqamj/MWF97rqn5bRCT9JBLo8bLzYx0ou/sady9x95JJkyZ9nLcQEZGLSCTQa4C8qO1coK53hpMArbmIiMSVSKDvAGaa2XQzGww8Cmzo3WFdnp4pKiIS67JXubh7m5k9CWwDMoBn3b3SzJ4I9j9jZplAKTAa6DCzbwCz3P1kTw9Y9dBFROK7bKADuPsWYEu3tmeiXjcQWYrpMzo+FxGJFbo7RUVEJL7QBbru/BcRiS90gd5J50RFRGKFNtBFRCRW6AJdSy4iIvGFLtA7ma5zERGJEdpAFxGRWKELdK24iIjEF7pA76SrXEREYoU20EVEJFboAl3PFBURiS90gS4iIvGFLtB1fC4iEl/oAr2TToqKiMQKbaCLiEis0AW6zomKiMQXukDvpFv/RURihTbQRUQkVggDXWsuIiLxhDDQI3SVi4hIrNAGuoiIxApdoOsqFxGR+EIX6J205CIiEiu0gS4iIrFCF+hacRERiS90gd5JNxaJiMQKXaDrpKiISHyhC/ROOikqIhIrtIEuIiKxQhfomWOGsnRuFiOHDEz2UEREUkpCgW5mi8zsLTM7aGZPxdlvZvYPwf5yM5vX80ONmJ8/jqc/N4/sscN66yNERELpsoFuZhnA08BiYBbwWTOb1a3bYmBm8LMa+KceHqeIiFxGIkfoC4CD7n7I3c8DzwEru/VZCfzUI94AxppZVg+PVURELiGRQM8BqqO2a4K2K+2Dma02s1IzK21qarrSsYqIyCUkEujxLhDsfjV4In1w9zXuXuLuJZMmTUpkfCIikqBEAr0GyIvazgXqPkYfERHpRYkE+g5gpplNN7PBwKPAhm59NgCPB1e7LASa3b2+h8cqIiKXcNmLud29zcyeBLYBGcCz7l5pZk8E+58BtgBLgIPAWeDLvTdkERGJJ6G7c9x9C5HQjm57Juq1A/+xZ4cmIiJXwjxJ1a7MrAl4/2P++kTgSA8OJ+w0H7E0HxdoLmKlw3zku3vcq0qSFuhXw8xK3b0k2eNIFZqPWJqPCzQXsdJ9PkJXy0VEROJToIuIpImwBvqaZA8gxWg+Ymk+LtBcxErr+QjlGrqIiHxUWI/QRUSkGwW6iEiaCF2gX+5hG+nAzJ41s8NmVhHVNt7MXjazt4M/x0Xt+1YwH2+Z2b1R7fPNbG+w7x/MwvkkVjPLM7Nfm9k+M6s0s/8UtPe7OTGzoWb2ppmVBXPxV0F7v5uLaGaWYWa7zWxTsN0/58PdQ/NDpPTAO8A1wGCgDJiV7HH1wve8DZgHVES1/R3wVPD6KeBvg9ezgnkYAkwP5icj2PcmcAuRapgvAYuT/d0+5nxkAfOC16OAA8H37ndzEox7ZPB6EPAHYGF/nItu8/JfgH8DNgXb/XI+wnaEnsjDNkLP3V8DjnVrXgn8JHj9E+C+qPbn3L3F3d8lUk9nQfCAkdHu/rpH/rb+NOp3QsXd6919V/D6FLCPSL39fjcnHnE62BwU/Dj9cC46mVkusBT4UVRzv5yPsAV6Qg/SSFNTPKhgGfw5OWi/2JzkBK+7t4eamU0DiokcmfbLOQmWF/YAh4GX3b3fzkXg74E/BTqi2vrlfIQt0BN6kEY/c7E5Sbu5MrORwAvAN9z95KW6xmlLmzlx93Z3LyLy3IEFZjbnEt3Tei7MbBlw2N13JvorcdrSZj7CFuj9+UEajZ3PaQ3+PBy0X2xOaoLX3dtDycwGEQnzf3X3tUFzv54Tdz8BvAosov/OxSeBFWb2HpEl2DvN7F/op/MRtkBP5GEb6WoD8MXg9ReB9VHtj5rZEDObDswE3gz+m3nKzBYGZ+sfj/qdUAnG/8/APnf/n1G7+t2cmNkkMxsbvB4G3AXspx/OBYC7f8vdc919GpE8+JW7f55+Oh9JPyt7pT9EHqRxgMjZ6e8kezy99B3/H1APtBI5cvgKMAH4JfB28Of4qP7fCebjLaLOzAMlQEWw7x8J7gwO2w9wK5H//pYDe4KfJf1xToACYHcwFxXAXwTt/W4u4szN7Vy4yqVfzodu/RcRSRNhW3IREZGLUKCLiKQJBbqISJpQoIuIpAkFuohImlCgi4ikCQW6iEia+P+nZmUFK4m0MwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(history['max_memory_allocation'])), np.array(history['max_memory_allocation']))\n",
    "plt.title('16bit - Manual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50000,\n",
       " 25000.0,\n",
       " 25008.6658425,\n",
       " 25017.33468887305,\n",
       " 25026.00654016039,\n",
       " 25034.68139740363,\n",
       " 25043.359261644735,\n",
       " 25052.040133926028,\n",
       " 25060.724015290198,\n",
       " 25069.410906780297,\n",
       " 25078.100809439733,\n",
       " 25086.793724312283,\n",
       " 25095.489652442076,\n",
       " 25104.188594873613,\n",
       " 25112.890552651752,\n",
       " 25121.59552682171,\n",
       " 25130.30351842908,\n",
       " 25139.014528519794,\n",
       " 25147.728558140167,\n",
       " 25156.44560833687,\n",
       " 25165.165680156937,\n",
       " 25173.888774647763,\n",
       " 25182.614892857106,\n",
       " 25191.34403583309,\n",
       " 25200.076204624205,\n",
       " 25208.811400279297,\n",
       " 25217.54962384758,\n",
       " 25226.290876378625,\n",
       " 25235.03515892238,\n",
       " 25243.782472529147,\n",
       " 25252.532818249594,\n",
       " 25261.286197134756,\n",
       " 25270.04261023603,\n",
       " 25278.80205860517,\n",
       " 25287.564543294313,\n",
       " 25296.33006535594,\n",
       " 25305.09862584292,\n",
       " 25313.87022580846,\n",
       " 25322.64486630615,\n",
       " 25331.422548389943,\n",
       " 25340.203273114155,\n",
       " 25348.987041533466,\n",
       " 25357.773854702926,\n",
       " 25366.563713677944,\n",
       " 25375.356619514303,\n",
       " 25384.152573268144,\n",
       " 25392.95157599598,\n",
       " 25401.753628754686,\n",
       " 25410.55873260151,\n",
       " 25419.366888594057,\n",
       " 25428.178097790307,\n",
       " 25436.9923612486,\n",
       " 25445.809680027654,\n",
       " 25454.63005518654,\n",
       " 25463.4534877847,\n",
       " 25472.279978881947,\n",
       " 25481.109529538462,\n",
       " 25489.94214081479,\n",
       " 25498.777813771845,\n",
       " 25507.61654947091,\n",
       " 25516.458348973632,\n",
       " 25525.30321334203,\n",
       " 25534.151143638494,\n",
       " 25543.00214092577,\n",
       " 25551.856206266988,\n",
       " 25560.713340725633,\n",
       " 25569.57354536557,\n",
       " 25578.43682125102,\n",
       " 25587.303169446586,\n",
       " 25596.17259101723,\n",
       " 25605.045087028295,\n",
       " 25613.920658545478,\n",
       " 25622.799306634854,\n",
       " 25631.68103236287,\n",
       " 25640.565836796337,\n",
       " 25649.45372100244,\n",
       " 25658.344686048727,\n",
       " 25667.238733003127,\n",
       " 25676.13586293393,\n",
       " 25685.0360769098,\n",
       " 25693.939375999773,\n",
       " 25702.845761273253,\n",
       " 25711.755233800013,\n",
       " 25720.6677946502,\n",
       " 25729.583444894328,\n",
       " 25738.50218560329,\n",
       " 25747.424017848345,\n",
       " 25756.34894270112,\n",
       " 25765.27696123362,\n",
       " 25774.208074518217]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['loss_scales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2cf3943250>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start at 50000\n",
    "plt.plot(np.arange(len(history['loss_scales'])), np.array(history['loss_scales']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'epoch_setup': 0.05201363563537598,\n",
       "             'get_memory': 2.7656726837158203,\n",
       "             'data': 0.33777332305908203,\n",
       "             'forward': 3.838088035583496,\n",
       "             'loss': 0.4171772003173828,\n",
       "             'append_losses': 0.16142797470092773,\n",
       "             'scale_up_loss': 0.19323301315307617,\n",
       "             'backward': 4.858585596084595,\n",
       "             'check_overflow': 6.717507600784302,\n",
       "             'to_master_grads': 1.8401403427124023,\n",
       "             'scale_down_master': 1.280548095703125,\n",
       "             'opt_step': 1.050520420074463,\n",
       "             'zero_grad': 2.3038978576660156,\n",
       "             'to_model_params': 0.7826895713806152,\n",
       "             'batch_time': 26.805591583251953,\n",
       "             'append': 0.02852034568786621,\n",
       "             'epoch_end_time': 121.62642860412598,\n",
       "             'loop_end_time': 121.68244647979736,\n",
       "             'itemize_losses': 0.13239097595214844})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args.hidden_layer_dims = [10, 10, 10, 10, 10, 10, 10]\n",
    "# 500 epochs\"\n",
    "history['timing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'epoch_setup': 0.5203053951263428,\n",
       "             'get_memory': 39.34049868583679,\n",
       "             'data': 3.368065357208252,\n",
       "             'forward': 36.701812505722046,\n",
       "             'loss': 4.3080689907073975,\n",
       "             'append_losses': 1.6422150135040283,\n",
       "             'scale_up_loss': 1.8668906688690186,\n",
       "             'backward': 49.15003752708435,\n",
       "             'check_overflow': 68.1950352191925,\n",
       "             'to_master_grads': 18.668896198272705,\n",
       "             'scale_down_master': 12.61150598526001,\n",
       "             'opt_step': 11.313706398010254,\n",
       "             'zero_grad': 24.82761001586914,\n",
       "             'to_model_params': 7.760152101516724,\n",
       "             'batch_time': 285.14426708221436,\n",
       "             'append': 0.2956278324127197,\n",
       "             'epoch_end_time': 1222.9026436805725,\n",
       "             'loop_end_time': 1223.4631593227386,\n",
       "             'itemize_losses': 1.5110013484954834})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# args.hidden_layer_dims = [50, 50, 50, 50, 50, 50, 50]\n",
    "# 5000 epochs\"\n",
    "history['timing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiler Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked by cuda_memory_usage\n",
      "\n",
      "58.40 Mb\n",
      "##############################################\n",
      "model, aten::empty, forward, (26) last_X = torch.relu(last_X)\n",
      "7.03 Mb\n",
      "##############################################\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model, aten::relu, forward, (26) last_X = torch.relu(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model, aten::threshold, forward, (26) last_X = torch.relu(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model, ReluBackward0, forward, (26) last_X = torch.relu(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model, aten::threshold_backward, forward, (26) last_X = torch.relu(last_X)\n",
      "3.52 Mb\n",
      "##############################################\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "2.72 Mb\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "2.72 Mb\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "2.72 Mb\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "2.72 Mb\n",
      "##############################################\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "2.72 Mb\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "2.72 Mb\n",
      "##############################################\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "922.50 Kb\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "922.50 Kb\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "922.50 Kb\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "922.50 Kb\n",
      "##############################################\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "922.50 Kb\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "922.50 Kb\n",
      "##############################################\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model, aten::softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model, aten::_softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model, aten::empty_like, forward, (30) a = torch.softmax(z, dim=1)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model, aten::empty, forward, (30) a = torch.softmax(z, dim=1)\n",
      "450.00 Kb\n",
      "##############################################\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, aten::contiguous, forward, (30) a = torch.softmax(z, dim=1)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "0.0 b\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "rankByCriteria(prof, model, criteria='cuda_memory_usage', per_thread=False, per_inp_shapes=False, include_external=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran for 5 epochs\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                    forward         5.95%        2.533s        99.89%       42.555s       42.555s         356 b      -2.75 Mb       7.50 Mb      -2.63 Mb             1  \n",
      "                                   aten::to        11.99%        5.109s        38.71%       16.492s     182.985us     878.91 Kb           0 b       1.25 Mb           0 b         90125  \n",
      "                                aten::stack         0.37%     157.559ms        22.91%        9.760s     108.446ms       1.20 Mb           0 b           0 b           0 b            90  \n",
      "                            aten::unsqueeze        11.19%        4.766s        22.28%        9.491s     105.456us           0 b           0 b           0 b           0 b         90000  \n",
      "                        aten::empty_strided        14.76%        6.287s        14.76%        6.287s     139.122us     878.91 Kb     878.91 Kb       1.28 Mb       1.28 Mb         45190  \n",
      "                                aten::empty        12.86%        5.479s        12.86%        5.479s      59.023us     705.43 Kb     705.43 Kb      12.00 Mb      12.00 Mb         92837  \n",
      "                                aten::copy_        12.27%        5.226s        12.27%        5.228s     113.368us           0 b           0 b           0 b           0 b         46115  \n",
      "                           aten::as_strided        11.21%        4.776s        11.21%        4.776s      51.998us           0 b           0 b           0 b           0 b         91845  \n",
      "                              aten::detach_         5.42%        2.310s        10.71%        4.564s     101.403us           0 b           0 b           0 b           0 b         45005  \n",
      "                                 aten::set_         5.57%        2.372s         5.57%        2.372s      52.612us           0 b           0 b           0 b           0 b         45090  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 42.603s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked by cpu_time\n",
      "\n",
      "111.915s\n",
      "##############################################\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "233.925ms\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (24) last_X = linear_layer(last_X)\n",
      "233.925ms\n",
      "##############################################\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "49.134ms\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (24) last_X = linear_layer(last_X)\n",
      "49.134ms\n",
      "##############################################\n",
      "model, aten::relu, forward, (26) last_X = torch.relu(last_X)\n",
      "44.290ms\n",
      "##############################################\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "29.520ms\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (24) last_X = linear_layer(last_X)\n",
      "29.520ms\n",
      "##############################################\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "24.984ms\n",
      "##############################################\n",
      "model.scorer, aten::addmm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::addmm, forward, (28) z = self.scorer(last_X)\n",
      "24.984ms\n",
      "##############################################\n",
      "model, aten::threshold, forward, (26) last_X = torch.relu(last_X)\n",
      "22.477ms\n",
      "##############################################\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "22.443ms\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (24) last_X = linear_layer(last_X)\n",
      "22.443ms\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "19.520ms\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (24) last_X = linear_layer(last_X)\n",
      "19.520ms\n",
      "##############################################\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "19.104ms\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (24) last_X = linear_layer(last_X)\n",
      "19.104ms\n",
      "##############################################\n",
      "model, aten::softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "16.160ms\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "15.153ms\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "15.153ms\n",
      "##############################################\n",
      "model, aten::_softmax, forward, (30) a = torch.softmax(z, dim=1)\n",
      "13.311ms\n",
      "##############################################\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "12.858ms\n",
      "##############################################\n",
      "model.scorer, aten::t, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::t, forward, (28) z = self.scorer(last_X)\n",
      "12.858ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "10.860ms\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (24) last_X = linear_layer(last_X)\n",
      "10.860ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (26) last_X = torch.relu(last_X)\n",
      "10.517ms\n",
      "##############################################\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "10.231ms\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (24) last_X = linear_layer(last_X)\n",
      "10.231ms\n",
      "##############################################\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "9.279ms\n",
      "##############################################\n",
      "model.scorer, aten::stride, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::stride, forward, (28) z = self.scorer(last_X)\n",
      "9.279ms\n",
      "##############################################\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "8.297ms\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (24) last_X = linear_layer(last_X)\n",
      "8.297ms\n",
      "##############################################\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "6.949ms\n",
      "##############################################\n",
      "model.scorer, AddmmBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, AddmmBackward, forward, (28) z = self.scorer(last_X)\n",
      "6.949ms\n",
      "##############################################\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "6.104ms\n",
      "##############################################\n",
      "model.scorer, aten::transpose, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::transpose, forward, (28) z = self.scorer(last_X)\n",
      "6.104ms\n",
      "##############################################\n",
      "model, ReluBackward0, forward, (26) last_X = torch.relu(last_X)\n",
      "5.654ms\n",
      "##############################################\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "5.061ms\n",
      "##############################################\n",
      "model.scorer, aten::as_strided, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::as_strided, forward, (28) z = self.scorer(last_X)\n",
      "5.061ms\n",
      "##############################################\n",
      "model, aten::empty_like, forward, (30) a = torch.softmax(z, dim=1)\n",
      "5.043ms\n",
      "##############################################\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "4.866ms\n",
      "##############################################\n",
      "model.scorer, aten::expand, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::expand, forward, (28) z = self.scorer(last_X)\n",
      "4.866ms\n",
      "##############################################\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "4.786ms\n",
      "##############################################\n",
      "model.scorer, aten::mm, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::mm, forward, (28) z = self.scorer(last_X)\n",
      "4.786ms\n",
      "##############################################\n",
      "model, aten::threshold_backward, forward, (26) last_X = torch.relu(last_X)\n",
      "4.070ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "2.799ms\n",
      "##############################################\n",
      "model.scorer, aten::empty, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::empty, forward, (28) z = self.scorer(last_X)\n",
      "2.799ms\n",
      "##############################################\n",
      "model, aten::empty, forward, (30) a = torch.softmax(z, dim=1)\n",
      "2.701ms\n",
      "##############################################\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "2.536ms\n",
      "##############################################\n",
      "model.scorer, aten::resize_, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, aten::resize_, forward, (28) z = self.scorer(last_X)\n",
      "2.536ms\n",
      "##############################################\n",
      "model, aten::contiguous, forward, (30) a = torch.softmax(z, dim=1)\n",
      "2.160ms\n",
      "##############################################\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "1.825ms\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (24) last_X = linear_layer(last_X)\n",
      "1.825ms\n",
      "##############################################\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "675.108us\n",
      "##############################################\n",
      "model.scorer, TBackward, forward, (93) return F.linear(input, self.weight, self.bias)\n",
      "model, TBackward, forward, (28) z = self.scorer(last_X)\n",
      "675.108us\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "# ran for 5 epochs\n",
    "rankByCriteria(prof, model, criteria='cpu_time', per_thread=False, per_inp_shapes=False, include_external=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nvidia Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 22 21:49:52 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 000099D1:00:00.0 Off |                    0 |\r\n",
      "| N/A   54C    P0    58W / 149W |    338MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      4647      C   ...s/py37_pytorch/bin/python      335MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Ran without profiler\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   10240 B  |  276480 B  |  158332 KB |  158322 KB |\n",
      "|       from large pool |       0 B  |       0 B  |       0 KB |       0 KB |\n",
      "|       from small pool |   10240 B  |  276480 B  |  158332 KB |  158322 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   10240 B  |  276480 B  |  158332 KB |  158322 KB |\n",
      "|       from large pool |       0 B  |       0 B  |       0 KB |       0 KB |\n",
      "|       from small pool |   10240 B  |  276480 B  |  158332 KB |  158322 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|       from large pool |       0 KB |       0 KB |       0 KB |       0 B  |\n",
      "|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    2038 KB |    2038 KB |  160370 KB |  158332 KB |\n",
      "|       from large pool |       0 KB |       0 KB |       0 KB |       0 KB |\n",
      "|       from small pool |    2038 KB |    2038 KB |  160370 KB |  158332 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      20    |      82    |  157068    |  157048    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |      20    |      82    |  157068    |  157048    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      20    |      82    |  157068    |  157048    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |      20    |      82    |  157068    |  157048    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       1    |       1    |       1    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       4    |       7    |   72826    |   72822    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       4    |       7    |   72826    |   72822    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ran without profiler\n",
    "print(torch.cuda.memory_summary(cuda0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
