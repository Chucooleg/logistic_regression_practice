{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchucooleg\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import math\n",
    "from typing import Callable, Iterable, Tuple\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 1\n",
    "\n",
    "def construct_full_model(hparams):\n",
    "    '''\n",
    "    return: nn.Module. Take a sequence of input symbols and \n",
    "    return a sequence of output symbols\n",
    "    '''\n",
    "\n",
    "    # cloned\n",
    "    clone = copy.deepcopy\n",
    "    pff = Positiontwise_FF(d_model=hparams['d_model'], d_ff=hparams['d_ff'])\n",
    "    attn = MultiHeadAttention(\n",
    "        d_model=hparams['d_model'], \n",
    "        h=hparams['num_heads'], \n",
    "        attn_wt_dropout=hparams['attn_wt_dropout'],\n",
    "    )\n",
    "    layer_norm = LayerNorm(d_model=hparams['d_model'])\n",
    "\n",
    "    # shared\n",
    "    scaled_embed = ScaledEmbedding(hparams['vocab_size'], hparams['d_model'])\n",
    "    # position_encoder = PositionEncoder(\n",
    "    #     d_model=hparams['d_model'], \n",
    "    #     max_len=hparams['max_len'], \n",
    "    #     emb_var=torch.var(scaled_embed.embedding.weight)\n",
    "    # )\n",
    "    position_encoder = LearnedPositionEncoder(\n",
    "        d_model=hparams['d_model'], \n",
    "        max_len=hparams['max_len'], \n",
    "        emb_init_var=torch.var(scaled_embed.embedding.weight).cpu().item()\n",
    "    )\n",
    "    embed_dropout = nn.Dropout(hparams['embed_dropout'])\n",
    "\n",
    "    # full model\n",
    "    model = EncoderDecoder(\n",
    "        encoder=Encoder(\n",
    "            encoder_layer=EncoderLayer(\n",
    "                poswise_ff=clone(pff),\n",
    "                self_attn=clone(attn), \n",
    "                layer_norm=clone(layer_norm), \n",
    "                heads_dropout=hparams['heads_dropout'],\n",
    "                pff_dropout=hparams['pff_dropout']\n",
    "            ), \n",
    "            N_layers=hparams['N_enc'],\n",
    "            d_model=hparams['d_model'],\n",
    "        ),\n",
    "        decoder=Decoder(\n",
    "            decoder_layer=DecoderLayer(\n",
    "                poswise_ff=clone(pff),\n",
    "                self_attn=clone(attn), \n",
    "                cross_attn=clone(attn), \n",
    "                layer_norm=clone(layer_norm), \n",
    "                heads_dropout=hparams['heads_dropout'],\n",
    "                pff_dropout=hparams['pff_dropout']\n",
    "            ),\n",
    "            N_layers=hparams['N_dec'],\n",
    "            d_model=hparams['d_model'],\n",
    "        ),\n",
    "        classifier=Classifier(\n",
    "            shared_embed=scaled_embed.embedding\n",
    "        ),\n",
    "        inp_layer=nn.Sequential(\n",
    "            OrderedDict([('scaled_embed', scaled_embed), \n",
    "                        ('position_encoder', position_encoder),\n",
    "                        ('embed_dropout', embed_dropout)]\n",
    "            )\n",
    "        ),\n",
    "        out_layer=nn.Sequential(\n",
    "            OrderedDict([('scaled_embed', scaled_embed), \n",
    "                        ('position_encoder', position_encoder),\n",
    "                        ('embed_dropout', embed_dropout)]\n",
    "            )\n",
    "        ),\n",
    "        pad_idx=hparams['padding_idx']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 2\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, classifier, inp_layer, out_layer, pad_idx):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self.inp_layer = inp_layer\n",
    "        self.out_layer = out_layer\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    # def forward(self, X, Y, inp_pads, out_pads):\n",
    "    def forward(self, X, Y):\n",
    "        '''\n",
    "        Args\n",
    "        X : a sequence of input symbols. shape(batch_size=b, inp_len)\n",
    "        Y : a sequence of output symbols. shape(batch_size=b, out_len)\n",
    "            offset to the right by one position.\n",
    "        Returns\n",
    "        y_pred : predicted probabilities. shape(batch_size=b, out_len, V)\n",
    "                should be offset by one position to be fed into decoder.\n",
    "        '''\n",
    "        # shape(batch_size=b, inp_len)\n",
    "        inp_pads = (X == self.pad_idx).int()\n",
    "        # shape(batch_size=b, out_len)\n",
    "        out_pads = (Y == self.pad_idx).int()\n",
    "\n",
    "        # shape(b, inp_len, d_model)\n",
    "        encoder_out = self.encode(X, inp_pads)\n",
    "        # shape(b, out_len, d_model)\n",
    "        decoder_out = self.decode(encoder_out, Y, inp_pads, out_pads)\n",
    "        # shape (b, out_len, V)\n",
    "        out_logits = self.classifier(decoder_out)\n",
    "\n",
    "        return out_logits\n",
    "\n",
    "    def encode(self, X, inp_pads):\n",
    "        # shape(b, inp_len, d_model)\n",
    "        inp_embed = self.inp_layer(X)\n",
    "        # shape(b, inp_len, d_model)\n",
    "        encoder_out = self.encoder(inp_embed, inp_pads)\n",
    "        return encoder_out\n",
    "\n",
    "    def decode(self, encoder_out, Y, inp_pads, out_pads):\n",
    "        # shape(b, out_len, d_model)\n",
    "        out_embed = self.out_layer(Y)\n",
    "        # shape(b, out_len, d_model)\n",
    "        decoder_out = self.decoder(encoder_out, out_embed, inp_pads, out_pads)\n",
    "        return decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 3\n",
    "# http://karlstratos.com/notes/transformer17.pdf\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_layer, N_layers, d_model):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "            [copy.deepcopy(encoder_layer) for _ in range(N_layers)])\n",
    "        self.N_layers = N_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, inp_embedding, inp_pads):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        inp_embedding: Input embeddings. Already position encoded.\n",
    "                        shape (batch_size=b, inp_len, d_model)\n",
    "        inp_pads: Input pads. shape (batch_size=b, inp_len). 1s are padded.\n",
    "        Returns\n",
    "        encoder_out: output from encoder stack. \n",
    "                    shape (batch_size=b, inp_len, d_model)\n",
    "        \"\"\"\n",
    "        m, inp_len, d_model = inp_embedding.shape\n",
    "\n",
    "        # Make self-attn mask\n",
    "        self_attn_mask = make_attn_mask(inp_pads, inp_pads, mask_forward=False)\n",
    "\n",
    "        # Initiate encoder output tensor\n",
    "        encoder_out = torch.empty(\n",
    "            m, self.N_layers, inp_len, self.d_model).type_as(inp_embedding)\n",
    "\n",
    "        # Loop through layers in stack\n",
    "        last_z = inp_embedding\n",
    "        for l, encoder_layer in enumerate(self.encoder_layers):\n",
    "            # shape (b, inp_len, d_model)\n",
    "            last_z, _ = encoder_layer(last_z, self_attn_mask)\n",
    "#             print(\"encoder layer\",l)\n",
    "            encoder_out[:, l, :, :] = last_z\n",
    "\n",
    "        return encoder_out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_layer, N_layers, d_model):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "            [copy.deepcopy(decoder_layer) for _ in range(N_layers)])\n",
    "        self.N_layers = N_layers\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, encoder_out, out_embedding, \n",
    "                inp_pads, out_pads, max_decode=100):\n",
    "        \"\"\"\n",
    "        Args\n",
    "        encoder_out: output from encoder stack.\n",
    "                    shape (batch_size=b, N_enc, inp_len, d_model)\n",
    "        out_embedding: Output embedding. Shape (batch_size=b, out_len, d_model)\n",
    "                    Already position encoded. Offset by one position.\n",
    "        inp_pads: Input pads. shape (batch_size=b, inp_len). 1s are padded.\n",
    "        out_pads: Input pads. shape (batch_size=b, out_len). 1s are padded.\n",
    "        Returns\n",
    "            decoder_out: output from decoder stack\n",
    "        \"\"\"\n",
    "        # b, N_enc, inp_len, d_model = encoder_out.shape\n",
    "        # b, out_len, d_model = out_embedding.shape\n",
    "\n",
    "        self_attn_mask = make_attn_mask(out_pads, out_pads, mask_forward=True)\n",
    "        cross_attn_mask = make_attn_mask(out_pads, inp_pads, mask_forward=False)\n",
    "\n",
    "        # Loop through layers in stack\n",
    "        last_o = out_embedding\n",
    "        for l, decoder_layer in enumerate(self.decoder_layers):\n",
    "            # shape (b, out_len, d_model)\n",
    "            last_o, _, _ = decoder_layer(\n",
    "                last_o, \n",
    "                # encoder_out[:, -1, :, :],\n",
    "                encoder_out[:, l, :, :],\n",
    "                self_attn_mask, cross_attn_mask\n",
    "            )\n",
    "        decoder_output = last_o\n",
    "        return decoder_output\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, shared_embed):\n",
    "        '''\n",
    "        shared_embed: same embedding matrix as the input and output layers.\n",
    "                    shape(V, d_model)\n",
    "        '''\n",
    "        super(Classifier, self).__init__()\n",
    "        self.shared_embed = shared_embed\n",
    "\n",
    "    def forward(self, decoder_out):\n",
    "        '''\n",
    "        decoder_out: last layer output of decoder stack. \n",
    "                 shape(batch_size=b, out_len, d_model)\n",
    "        '''\n",
    "        # shape (b, out_len, d_model) mm (d_model, V) = (b, out_len, V)\n",
    "        logits = decoder_out.matmul(self.shared_embed.weight.t())\n",
    "        # # shape (b, out_len, V) too expensive to compute everytime\n",
    "        # probs = torch.softmax(logits, dim=-1)\n",
    "        return logits #, probs\n",
    "\n",
    "\n",
    "class ScaledEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, V, d_model):\n",
    "        super(ScaledEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(V, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        '''\n",
    "        tokens: shape (batch_size=b, len)\n",
    "        '''\n",
    "        # shape (b, len, d_model)\n",
    "        embedded = self.embedding(tokens) * math.sqrt(self.d_model)\n",
    "        if torch.max(embedded) > 2000.:\n",
    "            import pdb; pdb.set_trace()\n",
    "        return embedded\n",
    "\n",
    "\n",
    "class PositionEncoder(nn.Module):\n",
    "    # Alternative implementation\n",
    "    # https://github.com/jalammar/jalammar.github.io/blob/master/notebookes/transformer/transformer_positional_encoding_graph.ipynb\n",
    "\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionEncoder, self).__init__()\n",
    "        # even\n",
    "        # i = 0, 2, 4, 6, ..., 510\n",
    "        # j = 0, 1, 2, 3, ..., 255\n",
    "        # PE(pos, i=2j) = sin(pos/10000**(2*j/d_model))\n",
    "        # odd\n",
    "        # i = 1, 3, 5, 7, ..., 511\n",
    "        # j = 0, 1, 2, 3, ..., 255\n",
    "        # PE(pos, i=2j+1) = cos(pos/10000**(2*j/d_model))\n",
    "        # shape(256,)\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.register_buffer(\n",
    "            name=\"positional_encoding\", \n",
    "            tensor=self.make_encodings(self.d_model, self.max_len)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def make_encodings(d_model, max_len):\n",
    "        # shape (d_model/2)\n",
    "        div_terms = torch.pow(\n",
    "            10000, \n",
    "            2*torch.arange(start=0, # j = 0\n",
    "                       end=d_model/2 # j = 255\n",
    "            )/d_model\n",
    "        )\n",
    "\n",
    "        # shape (max_len,) -> shape (max_len, d_model)\n",
    "        positions = torch.arange(\n",
    "            max_len\n",
    "            ).unsqueeze(-1).expand(-1, d_model)\n",
    "\n",
    "        # shape (max_len, d_model)\n",
    "        positional_encoding = torch.empty(\n",
    "            max_len, d_model, dtype=torch.float, \n",
    "        )\n",
    "    \n",
    "        # shape (max_len, d_model/2)\n",
    "        pos_at_even_dims = positions[:, ::2]\n",
    "        # shape (max_len, d_model/2)\n",
    "        pos_at_odd_dims  = positions[:, 1::2]\n",
    "\n",
    "        # shape (max_len, d_model/2)\n",
    "        div_terms_expand = div_terms.unsqueeze(0).expand(max_len, -1)\n",
    "\n",
    "        # shape (max_len, d_model/2)\n",
    "        positional_encoding[:, ::2] = torch.sin(pos_at_even_dims / div_terms_expand)\n",
    "        # shape (max_len, d_model/2)\n",
    "        positional_encoding[:, 1::2] = torch.cos(pos_at_odd_dims / div_terms_expand)\n",
    "\n",
    "        # shape (max_len, d_model)\n",
    "        return positional_encoding\n",
    "\n",
    "    def forward(self, embedded):\n",
    "        '''\n",
    "        embedded: shape (batch_size=b, len, d_model)\n",
    "        '''\n",
    "        b, len, d_model = embedded.shape\n",
    "        assert len <= self.max_len\n",
    "        # shape (batch_size=b, len, d_model)\n",
    "        positional_encoding = (\n",
    "            self.positional_encoding[:len, :].unsqueeze(0).expand(b, -1, -1)\n",
    "        )\n",
    "        # shape (batch_size=b, len, d_model)\n",
    "        return positional_encoding + embedded\n",
    "\n",
    "    \n",
    "class LearnedPositionEncoder(nn.Module):\n",
    "    '''Learned, instead of sinusoidal position encoder'''\n",
    "\t\n",
    "    def __init__(self, d_model, max_len, emb_init_var):\n",
    "\t    super().__init__()\n",
    "\t    self.pos_embedding = nn.Parameter(\n",
    "            torch.nn.init.normal_(\n",
    "                torch.zeros(max_len, d_model), \n",
    "\t\t\t    mean=0.0, \n",
    "\t\t\t    std=(emb_init_var/2)**(0.5))\n",
    "\t    )\n",
    "\t\t\n",
    "    def forward(self, embedded):\n",
    "\t    '''\n",
    "\t    embedded: shape (batch_size=b, len, d_model)\n",
    "\t    '''\n",
    "\t    b, inp_len, d_model = embedded.shape\n",
    "\t    # shape (1, len, d_model)\n",
    "\t    pos_embeddings = self.pos_embedding[:inp_len, :].unsqueeze(0)\n",
    "\t    # use broadcasting\n",
    "\t    # shape (b, len, d_model)\n",
    "\t    return embedded + pos_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing positional encoder\n",
    "\n",
    "def test_positional_encoder(PositionEncoder, max_len=10, d_model=64):\n",
    "    # test positional encoding\n",
    "    b, len, d_model = 20, max_len, d_model\n",
    "    embedding = torch.randn(b, len, d_model)\n",
    "    pos_enc = PositionEncoder(d_model, 50)\n",
    "    positional_encoding = pos_enc.positional_encoding\n",
    "    plot_positional_encoding(positional_encoding)\n",
    "\n",
    "def plot_positional_encoding(positional_encoding):\n",
    "    '''\n",
    "    positional_encoding: tensor shape (len, d_model)\n",
    "    '''\n",
    "\n",
    "    tokens, dimensions = positional_encoding.shape\n",
    "  \n",
    "    pos_encoding = positional_encoding.unsqueeze(0).cpu().numpy()\n",
    "\n",
    "    print (pos_encoding.shape)\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.pcolormesh(pos_encoding[0], cmap='viridis')\n",
    "    plt.xlabel('Embedding Dimensions')\n",
    "    plt.xlim((0, dimensions))\n",
    "    plt.ylim((tokens,0))\n",
    "    plt.ylabel('Token Position')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "test_positional_encoder(PositionEncoder, d_model=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 4\n",
    "# http://karlstratos.com/notes/transformer17.pdf\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    '''\n",
    "    single layer encoder\n",
    "    '''\n",
    "    def __init__(self, poswise_ff, self_attn, layer_norm,\n",
    "                heads_dropout, pff_dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.poswise_ff = poswise_ff\n",
    "        self.self_attn = self_attn\n",
    "        self.layer_norms = nn.ModuleList([copy.deepcopy(layer_norm) for _ in range(2)])\n",
    "        self.heads_dropout = nn.Dropout(heads_dropout)\n",
    "        self.pff_dropout = nn.Dropout(pff_dropout)\n",
    "\n",
    "    def forward(self, z_lm1, self_attn_mask):\n",
    "        '''\n",
    "        z_lm1 : last encoder layer activations. shape (batch_size=b, inp_len, d_model)\n",
    "        '''\n",
    "\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_h, self_attn_wts = self.self_attn(z_lm1, z_lm1, self_attn_mask)\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_h_norm = self.layer_norms[0](z_lm1 + self.heads_dropout(z_lm1_h))\n",
    "        # (b, inp_len, d_model)\n",
    "        z_lm1_ff = self.poswise_ff(z_lm1_h_norm)\n",
    "        # (b, inp_len, d_model)\n",
    "        z_l = self.layer_norms[1](z_lm1_h_norm + self.pff_dropout(z_lm1_ff))\n",
    "        \n",
    "        if torch.isinf(z_l).any() or torch.isnan(z_l).any():\n",
    "            print(\"z_l is nan or inf\")\n",
    "            import pdb; pdb.set_trace()\n",
    "        \n",
    "        return z_l, self_attn_wts\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    '''\n",
    "    single layer decoder\n",
    "    '''\n",
    "    def __init__(self, poswise_ff, self_attn, cross_attn, \n",
    "                layer_norm, heads_dropout, pff_dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.poswise_ff = poswise_ff\n",
    "        self.self_attn = self_attn\n",
    "        self.cross_attn = cross_attn\n",
    "        self.layer_norms = nn.ModuleList([copy.deepcopy(layer_norm) for _ in range(3)])\n",
    "        self.heads_dropout = nn.Dropout(heads_dropout)\n",
    "        self.pff_dropout = nn.Dropout(pff_dropout)\n",
    "\n",
    "    def forward(self, o_lm1, encoder_l_output, self_attn_mask, cross_attn_mask):\n",
    "        '''\n",
    "        o_lm1 : last decoder layer activations. \n",
    "            shape (batch_size=b, out_len, d_model).\n",
    "        encoder_l_output : encoder output from at the same layer index. \n",
    "                       shape (batch_size=b, inp_len, d_model)\n",
    "        '''\n",
    "\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_self_h, self_attn_wts = self.self_attn(o_lm1, o_lm1, self_attn_mask)\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_self_h_norm = self.layer_norms[0](o_lm1 + self.heads_dropout(o_lm1_self_h))\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_cross_h, cross_attn_wts = self.cross_attn(o_lm1_self_h_norm, encoder_l_output, cross_attn_mask)\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_cross_h_norm = self.layer_norms[1](o_lm1_self_h_norm + self.heads_dropout(o_lm1_cross_h))\n",
    "        # (b, out_len, d_model)\n",
    "        o_lm1_ff = self.poswise_ff(o_lm1_cross_h_norm)\n",
    "        # (b, out_len, d_model)\n",
    "        o_l = self.layer_norms[2](o_lm1_cross_h_norm + self.pff_dropout(o_lm1_ff))\n",
    "        return o_l, self_attn_wts, cross_attn_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code Depth 5\n",
    "# https://arxiv.org/pdf/1607.06450.pdf\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    '''Layer Normalization'''\n",
    "\n",
    "    def __init__(self, d_model, epsilon=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gain = nn.Parameter(torch.ones(d_model))\n",
    "        self.bias = nn.Parameter(torch.zeros(d_model))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x : shape (m, len, d_model)\n",
    "        Returns:\n",
    "            whitened_x : shape (m, len, d_model)\n",
    "        '''\n",
    "        # (m, len, 1)\n",
    "        mu = torch.mean(x, dim=-1, keepdim=True)\n",
    "        std = torch.std(x, dim=-1, keepdim=True)\n",
    "        # (m, len, d_model)\n",
    "        whitened_x = self.gain * (x - mu / (std + self.epsilon)) + self.bias\n",
    "        return whitened_x\n",
    "\n",
    "\n",
    "class Positiontwise_FF(nn.Module):\n",
    "    '''Pointwise FeedForward / Fat-RELU'''\n",
    "\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(Positiontwise_FF, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x : shape (m, len, d_model)\n",
    "        Returns:\n",
    "            shape (m, len, d_model)\n",
    "        '''\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multihead Attention'''\n",
    "\n",
    "    def __init__(self, d_model, h, attn_wt_dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.h = h\n",
    "        self.d_model = d_model\n",
    "        # d_k, same as d_q, d_v\n",
    "        self.d_k = int(d_model / h)\n",
    "        \n",
    "        ############################################################\n",
    "        # Break symmetry\n",
    "        \n",
    "        # template for WQ, WK, WV, WO projection matrices\n",
    "        # shape (d_model, d_k * h = d_model)\n",
    "        make_projection = lambda: nn.Linear(d_model, d_model, bias=True)\n",
    "        # make WQ, WK, WV, WO\n",
    "        self.projections_QKVO = nn.ModuleList([make_projection() for _ in range(4)])\n",
    "        ############################################################\n",
    "#         # simply use clone\n",
    "    \n",
    "#         # shape (d_model, d_k * h = d_model)\n",
    "#         projection = nn.Linear(d_model, d_model, bias=True)\n",
    "#         # clone projection to become WQ, WK, WV, WO\n",
    "#         self.projections_QKVO = nn.ModuleList([copy.deepcopy(projection) for _ in range(4)]) \n",
    "        ############################################################\n",
    "        # initialize WO as zeros to start training w/ identity function\n",
    "        self.projections_QKVO[3].weight.data = self.projections_QKVO[3].weight.data * 0.0\n",
    "        self.projections_QKVO[3].bias.data = self.projections_QKVO[3].bias.data * 0.0\n",
    "        ############################################################       \n",
    "        \n",
    "        self.attn_wt_dropout = nn.Dropout(p=attn_wt_dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, X, Y, mask):\n",
    "        '''\n",
    "        Args:\n",
    "            X : Attender. shape (batch_size=b, attender len=n, d_model)\n",
    "            Y : Attendee. shape (batch_size=b, attendee len=m, d_model)\n",
    "        Return:\n",
    "            attn_V : shape (b, n, h*d_k=d_model)\n",
    "        '''\n",
    "        b, n, d_model = X.shape\n",
    "\n",
    "        # Project X and Y to Q, K, V matrices\n",
    "        # Step 1 W(vals)\n",
    "        # XQ shape(b, n, d_k *h = d_model)\n",
    "        # YK shape(b, m, d_k *h = d_model)\n",
    "        # YV shape(b, m, d_k *h = d_model)\n",
    "        # Step 2 reshape()\n",
    "        # XQ shape(b, n, h, d_k)\n",
    "        # YK shape(b, m, h, d_k)\n",
    "        # YV shape(b, m, h, d_k)\n",
    "        # Step 3 swap axis with transpose()\n",
    "        # XQ shape(b, h, n, d_k)\n",
    "        # YK shape(b, h, m, d_k)\n",
    "        # YV shape(b, h, m, d_k)\n",
    "        XQ, YK, YV = [\n",
    "                      W(vals).reshape(b, -1, self.h, self.d_k)\n",
    "                      .transpose(1, 2) \n",
    "                      for (W, vals) in zip(self.projections_QKVO[:3], (X, Y, Y))]\n",
    "\n",
    "        # attention weighted values, attention weights\n",
    "        # shape (b, n, h, d_k), (b, h, n, m)\n",
    "        concat_V, attn = dotproduct_attention(\n",
    "            XQ, YK, YV, mask, self.attn_wt_dropout)\n",
    "        # shape (b, n, h*d_k=d_model)\n",
    "        concat_V = concat_V.reshape(b, n, -1)\n",
    "\n",
    "        # project by WO, shape (b, n, h*d_k=d_model)\n",
    "        attn_V = self.projections_QKVO[3](concat_V)\n",
    "   \n",
    "        return attn_V, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[[0., 1., 0.],\n",
      "         [0., 1., 0.],\n",
      "         [1., 1., 0.]]])\n",
      "alpha\n",
      " tensor([[[[-1.0231,  0.0260,  0.2767],\n",
      "          [ 0.7859,  0.2193,  0.9244],\n",
      "          [-0.5686,  1.7561,  1.9875]],\n",
      "\n",
      "         [[-0.5513, -0.7215,  0.3740],\n",
      "          [ 0.9782,  1.1411, -0.4604],\n",
      "          [-0.0315,  0.7704, -0.9848]]]])\n",
      "mask_stack\n",
      " tensor([[[[0., 1., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[0., 1., 0.],\n",
      "          [0., 1., 0.],\n",
      "          [1., 1., 0.]]]])\n",
      "alpha_masked\n",
      " tensor([[[[-1.0231e+00, -1.0000e+04,  2.7667e-01],\n",
      "          [ 7.8594e-01, -1.0000e+04,  9.2435e-01],\n",
      "          [-1.0000e+04, -1.0000e+04,  1.9875e+00]],\n",
      "\n",
      "         [[-5.5126e-01, -1.0000e+04,  3.7404e-01],\n",
      "          [ 9.7823e-01, -1.0000e+04, -4.6042e-01],\n",
      "          [-1.0000e+04, -1.0000e+04, -9.8484e-01]]]])\n",
      "beta\n",
      " tensor([[[[0.2142, 0.0000, 0.7858],\n",
      "          [0.4655, 0.0000, 0.5345],\n",
      "          [0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.2839, 0.0000, 0.7161],\n",
      "          [0.8082, 0.0000, 0.1918],\n",
      "          [0.0000, 0.0000, 1.0000]]]])\n",
      "wt_V\n",
      " tensor([[[[ 0.0503,  1.3734,  1.3906,  1.1347, -1.4249],\n",
      "          [ 0.2252,  0.0178,  1.1088, -1.3340, -0.2037]],\n",
      "\n",
      "         [[ 0.3770,  1.4147,  0.6841,  0.8578, -1.6775],\n",
      "          [-0.3468, -1.9870,  0.6939, -1.2022,  0.5139]],\n",
      "\n",
      "         [[-0.2282,  1.3382,  1.9929,  1.3708, -1.2096],\n",
      "          [ 0.5349,  1.1031,  1.3334, -1.4053, -0.5922]]]])\n",
      "ref wt_V\n",
      " tensor([[[[ 0.0503,  1.3734,  1.3906,  1.1347, -1.4249],\n",
      "          [ 0.2252,  0.0178,  1.1088, -1.3340, -0.2037]],\n",
      "\n",
      "         [[ 0.3770,  1.4147,  0.6841,  0.8578, -1.6775],\n",
      "          [-0.3468, -1.9870,  0.6939, -1.2022,  0.5139]],\n",
      "\n",
      "         [[-0.2282,  1.3382,  1.9929,  1.3708, -1.2096],\n",
      "          [ 0.5349,  1.1031,  1.3334, -1.4053, -0.5922]]]])\n",
      "ref wt_V\n",
      " torch.Size([1, 2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "## Code Depth 6\n",
    "\n",
    "def dotproduct_attention(Q, K, V, mask, beta_dropout, debug=False):\n",
    "    '''\n",
    "    Q: shape(batch_size=b, num heads=h, attender len=n, d_k)\n",
    "    K: shape(batch_size=b, num heads=h, attendee len=m, d_k)\n",
    "    V: shape(batch_size=b, num heads=h, attendee len=m, d_k)\n",
    "    mask: shape(batch_size=b, n, m)\n",
    "    beta_dropout: nn.Dropout().apply module\n",
    "    '''\n",
    "    b, h, n, d_k = Q.shape\n",
    "    b, h, m, d_k = K.shape\n",
    "\n",
    "    # XQ shape(b, h, n, d_k) matmul YK.T shape(b, h, d_k, m)\n",
    "    # = alpha shape (b, h, n, m)\n",
    "    alpha = torch.matmul(Q, K.transpose(-1, -2))/ math.sqrt(d_k)\n",
    "\n",
    "    # Apply mask \n",
    "    # (b, h, n, m)\n",
    "    mask_stack = mask.unsqueeze(1).expand(-1, h, -1, -1)\n",
    "    alpha_masked = torch.masked_fill(alpha, mask_stack==1, -1e4)\n",
    "\n",
    "    # normalize across attendee len m\n",
    "    # (b, h, n, m)\n",
    "    beta = beta_dropout(torch.softmax(alpha_masked, dim=-1))\n",
    "\n",
    "    # beta shape(b, h, n, m) bmm YK.T shape(b, h, m, d_k) = shape (b, h, n, d_k)\n",
    "    # transpose to (b, n, h, d_k)\n",
    "    wt_V = torch.matmul(beta, V).transpose(1, 2)\n",
    "\n",
    "    if debug:\n",
    "        print('alpha\\n', alpha)\n",
    "        print('mask_stack\\n', mask_stack)\n",
    "        print('alpha_masked\\n', alpha_masked)\n",
    "        print('beta\\n', beta)\n",
    "        print('wt_V\\n', wt_V)\n",
    "        \n",
    "    return wt_V, beta\n",
    "\n",
    "\n",
    "def ref_attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 1, -1e9)\n",
    "    p_attn = torch.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "def test_attention(attn_fn):\n",
    "    torch.manual_seed(123)\n",
    "    b, h, n, m, d_k = 1, 2, 3, 3, 5\n",
    "    Q = torch.randn(b, h, n, d_k)\n",
    "    K = torch.randn(b, h, m, d_k)\n",
    "    V = torch.randn(b, h, m, d_k)\n",
    "\n",
    "    # print('Q\\n', Q)\n",
    "    # print('K\\n', K)\n",
    "    # print('V\\n', V)\n",
    "\n",
    "    mask = torch.zeros((b, n, m))\n",
    "    mask[:,:,1] = 1\n",
    "    mask[:,2,:1] = 1\n",
    "    print('input', mask)\n",
    "\n",
    "    my_wt_V = dotproduct_attention(Q, K, V, mask, nn.Dropout(0.0), debug=True)\n",
    "    ref_wt_V, ref_p_attn = ref_attention(Q, K, V, mask, nn.Dropout(0.0))\n",
    "  \n",
    "    print('ref wt_V\\n', ref_wt_V.transpose(1, 2))\n",
    "    print('ref wt_V\\n', ref_wt_V.shape)\n",
    "\n",
    "test_attention(dotproduct_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Attention:\n",
      "attender_mask_expanded\n",
      " tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]]])\n",
      "attendee_mask_expanded\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]]])\n",
      "sum mask\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]]], dtype=torch.int32)\n",
      "--------------------------------------\n",
      "Self Attention:\n",
      "future_mask\n",
      " tensor([[0, 1, 1, 1],\n",
      "        [0, 0, 1, 1],\n",
      "        [0, 0, 0, 1],\n",
      "        [0, 0, 0, 0]])\n",
      "attender_mask_expanded\n",
      " tensor([[[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [1, 1, 1, 1]]])\n",
      "attendee_mask_expanded\n",
      " tensor([[[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 1]]])\n",
      "sum mask\n",
      " tensor([[[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1, 1],\n",
      "         [0, 0, 1, 1],\n",
      "         [0, 0, 0, 1],\n",
      "         [1, 1, 1, 1]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_attn_mask(attender_pads, attendee_pads, mask_forward=False, debug=False):\n",
    "    '''\n",
    "    Mask away attendee positions from attender.\n",
    "    Args:\n",
    "        attender_pads: shape(batch_size=b, attender len=n). 1s are pads.\n",
    "        attendee_pads: shape(batch_size=b, attender len=m). 1s are pads.\n",
    "    Return:\n",
    "        attn_mask: shape(b, n, m)\n",
    "    '''\n",
    "\n",
    "    b, n = attender_pads.shape\n",
    "    b, m = attendee_pads.shape\n",
    "\n",
    "    if mask_forward: \n",
    "        assert n == m\n",
    "        # shape (n, m)\n",
    "        try:\n",
    "            future_mask = torch.from_numpy(\n",
    "                np.triu(np.ones((n, m)), k=1)).type_as(attender_pads)\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "        # shape (b, n, m)\n",
    "        future_mask_expanded = future_mask.unsqueeze(0).expand(b, -1, -1)\n",
    "\n",
    "    # shape(b, n, m)\n",
    "    attender_mask_expanded = attender_pads.unsqueeze(-1).expand(-1, -1, m)\n",
    "    # shape(b, n, m)\n",
    "    attendee_mask_expanded = attendee_pads.unsqueeze(1).expand(-1, n, -1)\n",
    "\n",
    "    # shape(b, n, m)\n",
    "    if mask_forward: \n",
    "        sum_mask = attender_mask_expanded + attendee_mask_expanded + future_mask\n",
    "    else:\n",
    "        sum_mask = attender_mask_expanded + attendee_mask_expanded\n",
    "    sum_mask = (sum_mask > 0).type(torch.int)\n",
    "\n",
    "    if debug:\n",
    "        if mask_forward:\n",
    "            print('future_mask\\n',future_mask)\n",
    "        print('attender_mask_expanded\\n',attender_mask_expanded)\n",
    "        print('attendee_mask_expanded\\n',attendee_mask_expanded)\n",
    "        print('sum mask\\n', sum_mask)\n",
    "\n",
    "    return sum_mask\n",
    "\n",
    "\n",
    "def test_make_attn_mask():\n",
    "    #   attender_pads = torch.tensor([[0,0,0,1,1], [0,0,1,1,1], [0,0,0,0,0]])\n",
    "    attender_pads = torch.tensor([[0,0,0,1], [0,0,0,0], [0,0,0,1]])\n",
    "    attendee_pads = torch.tensor([[0,0,0,1], [0,0,0,0], [0,0,0,1]])\n",
    "    print('Cross Attention:')\n",
    "    make_attn_mask(attender_pads, attendee_pads, mask_forward=False, debug=True)\n",
    "    print('--------------------------------------')\n",
    "    print('Self Attention:')\n",
    "    make_attn_mask(attender_pads, attender_pads, mask_forward=True, debug=True)\n",
    "\n",
    "\n",
    "test_make_attn_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75.7293)\n",
      "tensor(75.7293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/playground/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/opt/conda/conda-bld/pytorch_1591914880026/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    }
   ],
   "source": [
    "class LabelSmoothedLoss(nn.Module):\n",
    "    '''\n",
    "    KL divergence Loss with Label Smoothing and Temperature scaling\n",
    "    '''\n",
    "\n",
    "    def __init__(self, K, padding_idx, smoothing_const=0.0, temperature_const=1.0):\n",
    "        super(LabelSmoothedLoss, self).__init__()\n",
    "        self.smoothing_const = smoothing_const\n",
    "        self.temperature_const = temperature_const\n",
    "        self.K = K\n",
    "        self.padding_idx = padding_idx\n",
    "        self.KLdiv_criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.logprob = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self, logits, labels, debug=False):\n",
    "        '''\n",
    "        logits: shape (batch_size=b, output_len=m, vocab_size=K)\n",
    "        labels: shape (batch_size=b, output_len=m)\n",
    "        '''\n",
    "        b, m, K = logits.shape\n",
    "\n",
    "        # Temperature Scaling\n",
    "        # shape (b*m, K)\n",
    "        scaled_logits = (logits / self.temperature_const).reshape(-1, K)\n",
    "        pred_logprobs = self.logprob(scaled_logits)\n",
    "\n",
    "        # Expand Labels to one-hot, Smooth the values\n",
    "        gt_probs_smoothed = torch.full(\n",
    "            size=(b*m, K), \n",
    "            # fill_value=self.smoothing_const / (K - 1), # more mathematicaly correct\n",
    "            fill_value=self.smoothing_const / (K - 2) #minus true and padding\n",
    "        ).type_as(logits)\n",
    "\n",
    "        gt_probs_smoothed = gt_probs_smoothed.scatter(\n",
    "            dim=-1, \n",
    "            index=labels.reshape(-1, 1), \n",
    "            value=(1. - self.smoothing_const),\n",
    "            # value=(1. - self.smoothing_const) + (self.smoothing_const / (K - 1)) # more mathematicaly correct\n",
    "        )\n",
    "        # Zero out padding idx\n",
    "        # shape (b*m, K)\n",
    "        gt_probs_smoothed[:, self.padding_idx] = 0.\n",
    "    \n",
    "        # Apply mask (e.g. if end of context is padded)\n",
    "        # shape (b*m, 1)\n",
    "        mask_ctx_pos = torch.nonzero(torch.flatten(labels) == self.padding_idx)\n",
    "        if mask_ctx_pos.dim() > 0:\n",
    "            # zero out rows for padded context positions\n",
    "            # e.g. word at position 10 is a pad, we zero out all probs for row 10\n",
    "            gt_probs_smoothed.index_fill_(\n",
    "                dim=0, index=mask_ctx_pos.squeeze(), value=0.0)\n",
    "\n",
    "        if debug:\n",
    "            print(scaled_logits)\n",
    "            print(labels_onehot)\n",
    "            print(mask_ctx_pos)\n",
    "\n",
    "        assert torch.all(torch.eq(torch.sum(gt_probs_smoothed, dim=-1), 1.))\n",
    "\n",
    "        return self.KLdiv_criterion(input=pred_logprobs, target=gt_probs_smoothed)\n",
    "\n",
    "\n",
    "# Only Use for verification\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "\n",
    "\n",
    "def test_loss_function(myLoss, refLoss, smoothing_const, temperature_const):\n",
    "    K = 3\n",
    "    padding_idx = 0\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "    myKL = myLoss(K, padding_idx, smoothing_const, temperature_const)\n",
    "    refKL = refLoss(K, padding_idx, smoothing_const)\n",
    "\n",
    "    labels = torch.tensor([[1, 1, 1, 2], [2, 2, 1, 1], [1, 1, 2, 1], [2, 1, 1, 1], [2, 1, 1, 2]])\n",
    "    inputs = torch.randn(5, 4, 3) * 4\n",
    "\n",
    "    ref_loss = refKL(F.log_softmax(inputs, dim=-1).reshape(-1, 3), torch.flatten(labels))\n",
    "    my_loss = myKL(inputs, labels )\n",
    "    #   if temperature_const == 1.0:\n",
    "    #     assert ref_loss == my_loss\n",
    "    print(ref_loss, )\n",
    "    print(my_loss)\n",
    "\n",
    "test_loss_function(myLoss=LabelSmoothedLoss, refLoss=LabelSmoothing, smoothing_const=0.1, temperature_const=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LRScheduledAdam(Optimizer):\n",
    "    \"\"\"\n",
    "    Implements Adam algorithm with learning rate schedule.\n",
    "    Modified based on hugging face implementation:\n",
    "    https://huggingface.co/transformers/_modules/transformers/optimization.html#AdamW\n",
    "\n",
    "    Parameters:\n",
    "        params (:obj:`Iterable[torch.nn.parameter.Parameter]`):\n",
    "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
    "        d_model (:obj:`int`):\n",
    "            Dimension of embedding vector.\n",
    "        warmup_steps (:obj:`int`):\n",
    "            Steps for warmup before learning rate peaks.\n",
    "        lr (:obj:`float`, `optional`, defaults to 0.):\n",
    "            The learning rate to use.\n",
    "        betas (:obj:`Tuple[float,float]`, `optional`, defaults to (0.9, 0.999)):\n",
    "            Adam's betas parameters (b1, b2).\n",
    "        eps (:obj:`float`, `optional`, defaults to 1e-6):\n",
    "            Adam's epsilon for numerical stability.\n",
    "        weight_decay (:obj:`float`, `optional`, defaults to 0):\n",
    "            Decoupled weight decay to apply.\n",
    "        correct_bias (:obj:`bool`, `optional`, defaults to `True`):\n",
    "            Whether ot not to correct bias in Adam (for instance, in Bert TF repository they use :obj:`False`).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Iterable[torch.nn.parameter.Parameter],\n",
    "        d_model: int,\n",
    "        warmup_steps: int,\n",
    "        lr: float = 0.,\n",
    "        betas: Tuple[float, float] = (0.9, 0.98),\n",
    "        eps: float = 1e-9,\n",
    "        correct_bias: bool = True,\n",
    "    ):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
    "        defaults = dict(\n",
    "            lr=lr, betas=betas, eps=eps, correct_bias=correct_bias)\n",
    "        super().__init__(params, defaults)\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def calc_step_size(self, step_num):\n",
    "        '''udpate lr'''\n",
    "        return (\n",
    "            self.d_model**(-0.5) * min(step_num**(-0.5), step_num * self.warmup_steps**(-1.5))\n",
    "        )\n",
    "\n",
    "    def step(self, closure: Callable = None):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (:obj:`Callable`, `optional`): A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state[\"step\"] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state[\"exp_avg\"] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state[\"exp_avg_sq\"] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
    "                beta1, beta2 = group[\"betas\"]\n",
    "\n",
    "                state[\"step\"] += 1\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                # In-place operations to update the averages at the same time\n",
    "                exp_avg.mul_(beta1).add_(grad, alpha=1.0 - beta1)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
    "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
    "\n",
    "                group[\"lr\"] = self.calc_step_size(state[\"step\"])\n",
    "                step_size = group[\"lr\"]\n",
    "                if group[\"correct_bias\"]:  # No bias correction for Bert\n",
    "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
    "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
    "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(exp_avg, denom, value=-step_size)\n",
    "        return loss\n",
    "\n",
    "def plot_lr(myOpt):\n",
    "    model = nn.Linear(2,3)\n",
    "    opts = [myOpt(model.parameters(), 512, 4000), \n",
    "            myOpt(model.parameters(), 512, 8000),\n",
    "            myOpt(model.parameters(), 256, 4000)]\n",
    "    plt.plot(np.arange(1, 20000), [[opt.calc_step_size(i) for opt in opts] for i in range(1, 20000)])\n",
    "    plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
    "\n",
    "plot_lr(LRScheduledAdam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_sequence(model, X, start_idx, pad_idx, max_len):\n",
    "    '''\n",
    "    Greedy Decoding\n",
    "    X : a sequence of input symbols. shape(batch_size=b, inp_len)\n",
    "    start_idx: int.\n",
    "    pad_idx: int.\n",
    "    max_len: int. Maximum context length for generation. Include <SOS> and <EOS>\n",
    "    '''\n",
    "\n",
    "    b, inp_len = X.shape\n",
    "    inp_pads = (X == pad_idx).int()\n",
    "\n",
    "    # encode inputs\n",
    "    # shape (b, inp_len, d_model)\n",
    "    encoded_memory = model.encode(X, inp_pads)\n",
    " \n",
    "    # shape (b, max_len) e.g. (b, 10)\n",
    "    Y = torch.ones(b, max_len).type_as(X) * pad_idx\n",
    "    Y[:,0] = start_idx\n",
    "    # shape (b, max_len)\n",
    "    out_pads = (Y == pad_idx).int()\n",
    "  \n",
    "    # generate one token at a time\n",
    "    for t in range(1, max_len): # (1 to 9)\n",
    "\n",
    "        # shape (b, t, d_model)\n",
    "        decoder_output = model.decode(encoded_memory, Y[:, :t], inp_pads, out_pads[:, :t])\n",
    "\n",
    "        # shape (b, t, V)\n",
    "        decoded_logits = model.classifier(decoder_output)\n",
    "        # decoded_probs = torch.softmax(decoded_logits, dim=-1)\n",
    "    \n",
    "        # shape (b,), (b,)\n",
    "        max_prob, max_idx = torch.max(decoded_logits[:, -1, :], dim=-1)\n",
    "    \n",
    "        # update Y, out_pads for next timestep\n",
    "        Y[:, t] = max_idx\n",
    "        out_pads[:, t] = (max_idx == pad_idx).int()\n",
    "\n",
    "    # shape (b, max_len)\n",
    "    # (1 to 9)\n",
    "    return Y[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_accuracy(start_idx, pad_idx, pred, labels):\n",
    "    '''\n",
    "    pred: shape (batch_size, max_len)\n",
    "    labels: shape (batch_size, max_len) \n",
    "    '''\n",
    "    assert not start_idx in labels, '<GO> should not be evaluated'\n",
    "\n",
    "    mask = 1 - (labels == pad_idx).int() # 0 means padded\n",
    "    tot_not_masked = torch.sum(mask)\n",
    "\n",
    "    same = (pred == labels).int() * mask\n",
    "    tot_correct = torch.sum(same)\n",
    "\n",
    "    return tot_correct * 1.0 / tot_not_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Lightning Module\n",
    "# https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=UIXLW8CO-W8w\n",
    "\n",
    "class Transformer(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        self.encdec_model = construct_full_model(hparams)\n",
    "        \n",
    "        self.loss_criterion = LabelSmoothedLoss(\n",
    "            K=hparams['vocab_size'],\n",
    "            padding_idx=hparams['padding_idx'],\n",
    "            smoothing_const=hparams['smoothing_const'],\n",
    "            temperature_const=hparams['temperature_const']\n",
    "        )\n",
    "\n",
    "        self.accuracy = partial(\n",
    "            multiclass_accuracy, hparams['start_idx'], hparams['padding_idx'])\n",
    "    \n",
    "    def log_metrics(self, metrics_dict):\n",
    "        for k, v in metrics_dict.items():\n",
    "            self.log(k, v)\n",
    "\n",
    "    def generate_sequence(self, X, start_idx, pad_idx, max_len):\n",
    "        # shape (b, max_len)\n",
    "        Y = greedy_decode_sequence(self.encdec_model, X, start_idx, pad_idx, max_len)\n",
    "        return Y\n",
    "\n",
    "    def get_max_memory_alloc(self):\n",
    "        devices_max_memory_alloc = {}\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            device = torch.device(f'cuda:{i}')\n",
    "            devices_max_memory_alloc[device] = torch.cuda.max_memory_allocated(device) / 1e6\n",
    "            torch.cuda.reset_max_memory_allocated(device)\n",
    "        return devices_max_memory_alloc\n",
    "    \n",
    "    def forward(self, X, Y, student_force_acc=False):\n",
    "        '''\n",
    "        X : (b, inp_len)\n",
    "        Y : (b, out_len)\n",
    "        '''\n",
    "\n",
    "        # fwd\n",
    "        # inp X[:,:]: tensor([1, 9, 6, 7, 9, 2])\n",
    "        # out Y[:, :-1]: tensor([1, 9, 6, 7, 9])\n",
    "        logits = self.encdec_model(X[:,:], Y[:, :-1])\n",
    "        \n",
    "        # loss\n",
    "        # target Y[:, 1:]: tensor([9, 6, 7, 9, 2])\n",
    "        loss = self.loss_criterion(logits, Y[:, 1:])\n",
    "\n",
    "        # acc\n",
    "        if student_force_acc:\n",
    "            y_hat = self.generate_sequence(\n",
    "                X, \n",
    "                hparams['start_idx'], \n",
    "                hparams['padding_idx'], \n",
    "                hparams['max_len'])         \n",
    "        else:\n",
    "            _, y_hat = torch.max(logits, dim=-1)\n",
    "\n",
    "        try:\n",
    "            acc = self.accuracy(y_hat, Y[:, 1:])\n",
    "        except:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        return loss, acc, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # (b, inp_len), (b, 1 GO + out_len) \n",
    "        X, Y = batch     \n",
    "        loss, acc, y_hat = self(X, Y)\n",
    "        # logs\n",
    "        step_metrics = {'train_loss': loss, 'train_acc':acc}\n",
    "        self.log_metrics(step_metrics)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # check if tensors are init at 16-bit here\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "        X, Y = batch\n",
    "        loss, acc, y_hat = self(X, Y, student_force_acc=True)\n",
    "        \n",
    "        # print sample\n",
    "        print('X:',X[0], '\\nY:',Y[0] ,'\\ninp X', X[0, :], '\\nout Y[:, :-1]', Y[0, :-1], \n",
    "              '\\ntgt Y', Y[0, 1:],'\\ny_hat', y_hat[0])\n",
    "        \n",
    "        # log\n",
    "        step_metrics = {'val_loss': loss, 'val_acc': acc}\n",
    "        devices_max_memory_alloc = self.get_max_memory_alloc()\n",
    "        for device, val in devices_max_memory_alloc.items():\n",
    "            step_metrics[f'step_max_memory_alloc_cuda:{device}'] = val\n",
    "        self.log_metrics(step_metrics)\n",
    "        return step_metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        X, Y = batch\n",
    "        loss, acc, y_hat = self(X, Y, student_force_acc=True)\n",
    "        # log\n",
    "        step_metrics = {'test_loss': loss, 'test_acc': acc}\n",
    "        # print('X:',X[0], '\\nY:',Y[0], '\\ny_hat', y_hat[0])\n",
    "        self.log_metrics(step_metrics)\n",
    "        return step_metrics\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        # log metrics\n",
    "        epoch_metrics = {\n",
    "            'avg_val_loss': avg_loss, \n",
    "            'avg_val_acc': avg_acc,\n",
    "            'encoder_pff_wt': self.encdec_model.encoder.encoder_layers[0].poswise_ff.linear1.weight[0,0],\n",
    "            'decoder_pff_wt': self.encdec_model.decoder.decoder_layers[0].poswise_ff.linear1.weight[0,0]}\n",
    "        self.log_metrics(epoch_metrics)\n",
    "        return epoch_metrics\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "        # log\n",
    "        epoch_metrics = {'avg_test_loss': avg_loss, 'avg_test_acc': avg_acc}\n",
    "        self.log_metrics(epoch_metrics)\n",
    "        return epoch_metrics\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        opt = LRScheduledAdam(\n",
    "            params=self.encdec_model.parameters(),\n",
    "            d_model=self.hparams['d_model'], \n",
    "            warmup_steps=self.hparams['warmup_steps'],\n",
    "            lr=0.,\n",
    "            betas=(\n",
    "                self.hparams['adam_beta1'], self.hparams['adam_beta2']),\n",
    "            eps=self.hparams['adam_epsilon'],\n",
    "            correct_bias=True\n",
    "        )\n",
    "        # opt = torch.optim.SGD(self.encdec_model.parameters(), lr=0.001, momentum=0.9)\n",
    "        # opt = AdamW(\n",
    "        #     params=self.encdec_model.parameters(),\n",
    "        #     lr=0.,\n",
    "        #     betas=(\n",
    "        #         self.hparams['adam_beta1'], self.hparams['adam_beta2']),\n",
    "        #     eps=self.hparams['adam_epsilon'],\n",
    "        # )\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataloaders\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    '''Toy Dataset. Input copying task.'''\n",
    "\n",
    "    def __init__(self, V=20, seed=0, context_len=6, tot_size=1000):\n",
    "        super(ToyDataset, self).__init__()\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        \n",
    "#         #############################################################\n",
    "#         # completely random series\n",
    "#         self.X = np.random.randint(3, V, size=(tot_size, context_len)) # [3, 49]\n",
    "#         self.X[:, 0] = 1 # <SOS>\n",
    "#         self.X[:, -1] = 2 # <EOS>\n",
    "#         self.Y = self.X[:,:].copy()\n",
    "        #############################################################\n",
    "        # reverse order\n",
    "        self.X = np.random.randint(3, V, size=(tot_size, context_len)) # [3, 49]\n",
    "        self.X[:, 0] = 1 # <SOS>\n",
    "        self.X[:, -1] = 2 # <EOS>\n",
    "        self.Y = self.X[:,::-1].copy()        \n",
    "        self.Y[:, 0] = 1 # <SOS>\n",
    "        self.Y[:, -1] = 2 # <EOS>  \n",
    "        #############################################################\n",
    "#         # + 1 series\n",
    "#         self.X = np.empty((tot_size, context_len))\n",
    "#         self.X[:, 1] = np.random.randint(3, V - (context_len - 3), size=(tot_size, ))\n",
    "#         for i in range(2, context_len):\n",
    "#             self.X[:, i] = self.X[:, i-1] + 1\n",
    "#         self.X[:, 0] = 1 # <SOS>\n",
    "#         self.X[:, -1] = 2 # <EOS>\n",
    "#         self.Y = self.X[:,:].copy()   \n",
    "#         #############################################################\n",
    "#         # sum of current X + last X\n",
    "#         self.X = np.empty((tot_size, context_len))\n",
    "#         self.X[:, 1:context_len] = np.random.randint(3, V//2+1, size=(tot_size,context_len-1))        \n",
    "#         self.X[:, 0] = 1 # <SOS>\n",
    "#         self.X[:, -1] = 2 # <EOS>\n",
    "#         self.Y = np.empty((tot_size, context_len))\n",
    "#         for i in range(1, context_len):\n",
    "#             self.Y[:, i] = self.X[:, i-1] + self.X[:, i]\n",
    "#         self.Y[:, 0] = 1 # <SOS>\n",
    "#         self.Y[:, -1] = 2 # <EOS>          \n",
    "#         #############################################################\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.from_numpy(self.X[idx, :]).long()\n",
    "        y = torch.from_numpy(self.Y[idx, :]).long()\n",
    "        return x, y\n",
    "\n",
    "toy_dataset = ToyDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples of datasets\n",
    "\n",
    "## replicate random\n",
    "```\n",
    "X\n",
    "(tensor([[ 1, 18,  3,  6,  6,  2],\n",
    "         [ 1,  7,  9, 15,  4,  2],\n",
    "         [ 1, 17,  8, 16, 11,  2],\n",
    "         [ 1,  8, 18, 18,  3,  2],\n",
    "         [ 1, 10,  3,  4, 12,  2],\n",
    "         [ 1,  6, 14,  5,  3,  2],\n",
    "         [ 1,  8,  9, 11, 18,  2],\n",
    "         [ 1, 13,  4,  4, 10,  2],\n",
    "         [ 1,  9, 14, 17,  3,  2],\n",
    "         [ 1, 15, 13, 14,  7,  2]]),\n",
    "Y\n",
    " tensor([[ 1, 18,  3,  6,  6,  2],\n",
    "         [ 1,  7,  9, 15,  4,  2],\n",
    "         [ 1, 17,  8, 16, 11,  2],\n",
    "         [ 1,  8, 18, 18,  3,  2],\n",
    "         [ 1, 10,  3,  4, 12,  2],\n",
    "         [ 1,  6, 14,  5,  3,  2],\n",
    "         [ 1,  8,  9, 11, 18,  2],\n",
    "         [ 1, 13,  4,  4, 10,  2],\n",
    "         [ 1,  9, 14, 17,  3,  2],\n",
    "         [ 1, 15, 13, 14,  7,  2]]))\n",
    "```\n",
    "\n",
    "\n",
    "## reversed random\n",
    "```\n",
    "(tensor([[ 1, 18,  3,  6,  6,  2],\n",
    "         [ 1,  7,  9, 15,  4,  2],\n",
    "         [ 1, 17,  8, 16, 11,  2],\n",
    "         [ 1,  8, 18, 18,  3,  2],\n",
    "         [ 1, 10,  3,  4, 12,  2],\n",
    "         [ 1,  6, 14,  5,  3,  2],\n",
    "         [ 1,  8,  9, 11, 18,  2],\n",
    "         [ 1, 13,  4,  4, 10,  2],\n",
    "         [ 1,  9, 14, 17,  3,  2],\n",
    "         [ 1, 15, 13, 14,  7,  2]]),\n",
    " tensor([[ 1,  6,  6,  3, 18,  2],\n",
    "         [ 1,  4, 15,  9,  7,  2],\n",
    "         [ 1, 11, 16,  8, 17,  2],\n",
    "         [ 1,  3, 18, 18,  8,  2],\n",
    "         [ 1, 12,  4,  3, 10,  2],\n",
    "         [ 1,  3,  5, 14,  6,  2],\n",
    "         [ 1, 18, 11,  9,  8,  2],\n",
    "         [ 1, 10,  4,  4, 13,  2],\n",
    "         [ 1,  3, 17, 14,  9,  2],\n",
    "         [ 1,  7, 14, 13, 15,  2]]))\n",
    "```\n",
    "\n",
    "\n",
    "## autoregressive +1 series\n",
    "```\n",
    "X\n",
    "(tensor([[ 1, 15, 16, 17, 18,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2],\n",
    "         [ 1,  3,  4,  5,  6,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 14, 15, 16, 17,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 10, 11, 12, 13,  2],\n",
    "         [ 1, 12, 13, 14, 15,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2]]),\n",
    "Y\n",
    " tensor([[ 1, 15, 16, 17, 18,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2],\n",
    "         [ 1,  3,  4,  5,  6,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 14, 15, 16, 17,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1, 10, 11, 12, 13,  2],\n",
    "         [ 1, 12, 13, 14, 15,  2],\n",
    "         [ 1,  6,  7,  8,  9,  2],\n",
    "         [ 1,  8,  9, 10, 11,  2]]))\n",
    "```\n",
    "\n",
    "\n",
    "## current of X + last of X series\n",
    "```\n",
    "X\n",
    "(tensor([[ 1,  7, 10,  8,  3,  2],\n",
    "         [ 1,  6,  6, 10,  4,  2],\n",
    "         [ 1,  8,  5,  7, 10,  2],\n",
    "         [ 1,  3,  3,  7,  5,  2],\n",
    "         [ 1,  9, 10, 10,  9,  2],\n",
    "         [ 1,  4,  8,  4,  8,  2],\n",
    "         [ 1,  4,  7,  6,  3,  2],\n",
    "         [ 1,  8,  9, 10, 10,  2],\n",
    "         [ 1,  5,  6,  3,  4,  2],\n",
    "         [ 1,  8,  6,  6,  9,  2]]),\n",
    "Y\n",
    " tensor([[ 1,  8, 17, 18, 11,  2],\n",
    "         [ 1,  7, 12, 16, 14,  2],\n",
    "         [ 1,  9, 13, 12, 17,  2],\n",
    "         [ 1,  4,  6, 10, 12,  2],\n",
    "         [ 1, 10, 19, 20, 19,  2],\n",
    "         [ 1,  5, 12, 12, 12,  2],\n",
    "         [ 1,  5, 11, 13,  9,  2],\n",
    "         [ 1,  9, 17, 19, 20,  2],\n",
    "         [ 1,  6, 11,  9,  7,  2],\n",
    "         [ 1,  9, 14, 12, 15,  2]]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataModule(pl.LightningDataModule):\n",
    "    # https://wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-Biases--Vmlldzo2NjQ1Mw\n",
    "\n",
    "    def __init__(self, batch_size, V, seed, context_len, tot_size):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.V = V\n",
    "        self.seed = seed\n",
    "        self.context_len = context_len\n",
    "        self.tot_size = tot_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage in None:\n",
    "            self.toy_train = ToyDataset(\n",
    "                V=self.V, seed=self.seed, \n",
    "                context_len=self.context_len, tot_size=self.tot_size)\n",
    "            self.toy_val = self.toy_train            \n",
    "            # self.toy_val = ToyDataset(\n",
    "            #     V=self.V, seed=42, \n",
    "            #     context_len=self.context_len, tot_size=self.batch_size*2) \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.toy_test = self.toy_train\n",
    "            # self.toy_test = ToyDataset(\n",
    "            #     V=self.V, seed=41, \n",
    "            #     context_len=self.context_len, tot_size=self.batch_size*2)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(self.toy_train, batch_size=self.batch_size, shuffle=False)\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.toy_val, batch_size=self.batch_size, shuffle=False)\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(self.toy_test, batch_size=self.batch_size, shuffle=False)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multihead Attention'''\n",
    "\n",
    "    def __init__(self, d_model, h, attn_wt_dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.h = h\n",
    "        self.d_model = d_model\n",
    "        # d_k, same as d_q, d_v\n",
    "        self.d_k = int(d_model / h)\n",
    "        \n",
    "        ############################################################\n",
    "#         # Break symmetry\n",
    "        \n",
    "#         # template for WQ, WK, WV, WO projection matrices\n",
    "#         # shape (d_model, d_k * h = d_model)\n",
    "#         make_projection = lambda: nn.Linear(d_model, d_model, bias=True)\n",
    "#         # make WQ, WK, WV, WO\n",
    "#         self.projections_QKVO = nn.ModuleList([make_projection() for _ in range(4)])\n",
    "        ############################################################\n",
    "        # simply use clone\n",
    "    \n",
    "        # shape (d_model, d_k * h = d_model)\n",
    "        projection = nn.Linear(d_model, d_model, bias=True)\n",
    "        # clone projection to become WQ, WK, WV, WO\n",
    "        self.projections_QKVO = nn.ModuleList([copy.deepcopy(projection) for _ in range(4)]) \n",
    "        ############################################################\n",
    "        # initialize WO as zeros to start training w/ identity function\n",
    "        self.projections_QKVO[3].weight.data = self.projections_QKVO[3].weight.data * 0.0\n",
    "        self.projections_QKVO[3].bias.data = self.projections_QKVO[3].bias.data * 0.0\n",
    "        ############################################################       \n",
    "        \n",
    "        self.attn_wt_dropout = nn.Dropout(p=attn_wt_dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, X, Y, mask):\n",
    "        '''\n",
    "        Args:\n",
    "            X : Attender. shape (batch_size=b, attender len=n, d_model)\n",
    "            Y : Attendee. shape (batch_size=b, attendee len=m, d_model)\n",
    "        Return:\n",
    "            attn_V : shape (b, n, h*d_k=d_model)\n",
    "        '''\n",
    "        b, n, d_model = X.shape\n",
    "\n",
    "        # Project X and Y to Q, K, V matrices\n",
    "        # Step 1 W(vals)\n",
    "        # XQ shape(b, n, d_k *h = d_model)\n",
    "        # YK shape(b, m, d_k *h = d_model)\n",
    "        # YV shape(b, m, d_k *h = d_model)\n",
    "        # Step 2 reshape()\n",
    "        # XQ shape(b, n, h, d_k)\n",
    "        # YK shape(b, m, h, d_k)\n",
    "        # YV shape(b, m, h, d_k)\n",
    "        # Step 3 swap axis with transpose()\n",
    "        # XQ shape(b, h, n, d_k)\n",
    "        # YK shape(b, h, m, d_k)\n",
    "        # YV shape(b, h, m, d_k)\n",
    "        XQ, YK, YV = [\n",
    "                      W(vals).reshape(b, -1, self.h, self.d_k)\n",
    "                      .transpose(1, 2) \n",
    "                      for (W, vals) in zip(self.projections_QKVO[:3], (X, Y, Y))]\n",
    "\n",
    "        # attention weighted values, attention weights\n",
    "        # shape (b, n, h, d_k), (b, h, n, m)\n",
    "        concat_V, attn = dotproduct_attention(\n",
    "            XQ, YK, YV, mask, self.attn_wt_dropout)\n",
    "        # shape (b, n, h*d_k=d_model)\n",
    "        concat_V = concat_V.reshape(b, n, -1)\n",
    "\n",
    "        # project by WO, shape (b, n, h*d_k=d_model)\n",
    "        attn_V = self.projections_QKVO[3](concat_V)\n",
    "   \n",
    "        return attn_V, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                                                                | Type                   | Params\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "0  | encdec_model                                                        | EncoderDecoder         | 14 M  \n",
      "1  | encdec_model.encoder                                                | Encoder                | 6 M   \n",
      "2  | encdec_model.encoder.encoder_layers                                 | ModuleList             | 6 M   \n",
      "3  | encdec_model.encoder.encoder_layers.0                               | EncoderLayer           | 3 M   \n",
      "4  | encdec_model.encoder.encoder_layers.0.poswise_ff                    | Positiontwise_FF       | 2 M   \n",
      "5  | encdec_model.encoder.encoder_layers.0.poswise_ff.linear1            | Linear                 | 1 M   \n",
      "6  | encdec_model.encoder.encoder_layers.0.poswise_ff.linear2            | Linear                 | 1 M   \n",
      "7  | encdec_model.encoder.encoder_layers.0.self_attn                     | MultiHeadAttention     | 1 M   \n",
      "8  | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO    | ModuleList             | 1 M   \n",
      "9  | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.0  | Linear                 | 262 K \n",
      "10 | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.1  | Linear                 | 262 K \n",
      "11 | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.2  | Linear                 | 262 K \n",
      "12 | encdec_model.encoder.encoder_layers.0.self_attn.projections_QKVO.3  | Linear                 | 262 K \n",
      "13 | encdec_model.encoder.encoder_layers.0.self_attn.attn_wt_dropout     | Dropout                | 0     \n",
      "14 | encdec_model.encoder.encoder_layers.0.layer_norms                   | ModuleList             | 2 K   \n",
      "15 | encdec_model.encoder.encoder_layers.0.layer_norms.0                 | LayerNorm              | 1 K   \n",
      "16 | encdec_model.encoder.encoder_layers.0.layer_norms.1                 | LayerNorm              | 1 K   \n",
      "17 | encdec_model.encoder.encoder_layers.0.heads_dropout                 | Dropout                | 0     \n",
      "18 | encdec_model.encoder.encoder_layers.0.pff_dropout                   | Dropout                | 0     \n",
      "19 | encdec_model.encoder.encoder_layers.1                               | EncoderLayer           | 3 M   \n",
      "20 | encdec_model.encoder.encoder_layers.1.poswise_ff                    | Positiontwise_FF       | 2 M   \n",
      "21 | encdec_model.encoder.encoder_layers.1.poswise_ff.linear1            | Linear                 | 1 M   \n",
      "22 | encdec_model.encoder.encoder_layers.1.poswise_ff.linear2            | Linear                 | 1 M   \n",
      "23 | encdec_model.encoder.encoder_layers.1.self_attn                     | MultiHeadAttention     | 1 M   \n",
      "24 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO    | ModuleList             | 1 M   \n",
      "25 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.0  | Linear                 | 262 K \n",
      "26 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.1  | Linear                 | 262 K \n",
      "27 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.2  | Linear                 | 262 K \n",
      "28 | encdec_model.encoder.encoder_layers.1.self_attn.projections_QKVO.3  | Linear                 | 262 K \n",
      "29 | encdec_model.encoder.encoder_layers.1.self_attn.attn_wt_dropout     | Dropout                | 0     \n",
      "30 | encdec_model.encoder.encoder_layers.1.layer_norms                   | ModuleList             | 2 K   \n",
      "31 | encdec_model.encoder.encoder_layers.1.layer_norms.0                 | LayerNorm              | 1 K   \n",
      "32 | encdec_model.encoder.encoder_layers.1.layer_norms.1                 | LayerNorm              | 1 K   \n",
      "33 | encdec_model.encoder.encoder_layers.1.heads_dropout                 | Dropout                | 0     \n",
      "34 | encdec_model.encoder.encoder_layers.1.pff_dropout                   | Dropout                | 0     \n",
      "35 | encdec_model.decoder                                                | Decoder                | 8 M   \n",
      "36 | encdec_model.decoder.decoder_layers                                 | ModuleList             | 8 M   \n",
      "37 | encdec_model.decoder.decoder_layers.0                               | DecoderLayer           | 4 M   \n",
      "38 | encdec_model.decoder.decoder_layers.0.poswise_ff                    | Positiontwise_FF       | 2 M   \n",
      "39 | encdec_model.decoder.decoder_layers.0.poswise_ff.linear1            | Linear                 | 1 M   \n",
      "40 | encdec_model.decoder.decoder_layers.0.poswise_ff.linear2            | Linear                 | 1 M   \n",
      "41 | encdec_model.decoder.decoder_layers.0.self_attn                     | MultiHeadAttention     | 1 M   \n",
      "42 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO    | ModuleList             | 1 M   \n",
      "43 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.0  | Linear                 | 262 K \n",
      "44 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.1  | Linear                 | 262 K \n",
      "45 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.2  | Linear                 | 262 K \n",
      "46 | encdec_model.decoder.decoder_layers.0.self_attn.projections_QKVO.3  | Linear                 | 262 K \n",
      "47 | encdec_model.decoder.decoder_layers.0.self_attn.attn_wt_dropout     | Dropout                | 0     \n",
      "48 | encdec_model.decoder.decoder_layers.0.cross_attn                    | MultiHeadAttention     | 1 M   \n",
      "49 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO   | ModuleList             | 1 M   \n",
      "50 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.0 | Linear                 | 262 K \n",
      "51 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.1 | Linear                 | 262 K \n",
      "52 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.2 | Linear                 | 262 K \n",
      "53 | encdec_model.decoder.decoder_layers.0.cross_attn.projections_QKVO.3 | Linear                 | 262 K \n",
      "54 | encdec_model.decoder.decoder_layers.0.cross_attn.attn_wt_dropout    | Dropout                | 0     \n",
      "55 | encdec_model.decoder.decoder_layers.0.layer_norms                   | ModuleList             | 3 K   \n",
      "56 | encdec_model.decoder.decoder_layers.0.layer_norms.0                 | LayerNorm              | 1 K   \n",
      "57 | encdec_model.decoder.decoder_layers.0.layer_norms.1                 | LayerNorm              | 1 K   \n",
      "58 | encdec_model.decoder.decoder_layers.0.layer_norms.2                 | LayerNorm              | 1 K   \n",
      "59 | encdec_model.decoder.decoder_layers.0.heads_dropout                 | Dropout                | 0     \n",
      "60 | encdec_model.decoder.decoder_layers.0.pff_dropout                   | Dropout                | 0     \n",
      "61 | encdec_model.decoder.decoder_layers.1                               | DecoderLayer           | 4 M   \n",
      "62 | encdec_model.decoder.decoder_layers.1.poswise_ff                    | Positiontwise_FF       | 2 M   \n",
      "63 | encdec_model.decoder.decoder_layers.1.poswise_ff.linear1            | Linear                 | 1 M   \n",
      "64 | encdec_model.decoder.decoder_layers.1.poswise_ff.linear2            | Linear                 | 1 M   \n",
      "65 | encdec_model.decoder.decoder_layers.1.self_attn                     | MultiHeadAttention     | 1 M   \n",
      "66 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO    | ModuleList             | 1 M   \n",
      "67 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.0  | Linear                 | 262 K \n",
      "68 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.1  | Linear                 | 262 K \n",
      "69 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.2  | Linear                 | 262 K \n",
      "70 | encdec_model.decoder.decoder_layers.1.self_attn.projections_QKVO.3  | Linear                 | 262 K \n",
      "71 | encdec_model.decoder.decoder_layers.1.self_attn.attn_wt_dropout     | Dropout                | 0     \n",
      "72 | encdec_model.decoder.decoder_layers.1.cross_attn                    | MultiHeadAttention     | 1 M   \n",
      "73 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO   | ModuleList             | 1 M   \n",
      "74 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.0 | Linear                 | 262 K \n",
      "75 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.1 | Linear                 | 262 K \n",
      "76 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.2 | Linear                 | 262 K \n",
      "77 | encdec_model.decoder.decoder_layers.1.cross_attn.projections_QKVO.3 | Linear                 | 262 K \n",
      "78 | encdec_model.decoder.decoder_layers.1.cross_attn.attn_wt_dropout    | Dropout                | 0     \n",
      "79 | encdec_model.decoder.decoder_layers.1.layer_norms                   | ModuleList             | 3 K   \n",
      "80 | encdec_model.decoder.decoder_layers.1.layer_norms.0                 | LayerNorm              | 1 K   \n",
      "81 | encdec_model.decoder.decoder_layers.1.layer_norms.1                 | LayerNorm              | 1 K   \n",
      "82 | encdec_model.decoder.decoder_layers.1.layer_norms.2                 | LayerNorm              | 1 K   \n",
      "83 | encdec_model.decoder.decoder_layers.1.heads_dropout                 | Dropout                | 0     \n",
      "84 | encdec_model.decoder.decoder_layers.1.pff_dropout                   | Dropout                | 0     \n",
      "85 | encdec_model.classifier                                             | Classifier             | 10 K  \n",
      "86 | encdec_model.classifier.shared_embed                                | Embedding              | 10 K  \n",
      "87 | encdec_model.inp_layer                                              | Sequential             | 13 K  \n",
      "88 | encdec_model.inp_layer.scaled_embed                                 | ScaledEmbedding        | 10 K  \n",
      "89 | encdec_model.inp_layer.position_encoder                             | LearnedPositionEncoder | 3 K   \n",
      "90 | encdec_model.inp_layer.embed_dropout                                | Dropout                | 0     \n",
      "91 | encdec_model.out_layer                                              | Sequential             | 13 K  \n",
      "92 | loss_criterion                                                      | LabelSmoothedLoss      | 0     \n",
      "93 | loss_criterion.KLdiv_criterion                                      | KLDivLoss              | 0     \n",
      "94 | loss_criterion.logprob                                              | LogSoftmax             | 0      \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/playground/lib/python3.7/site-packages/torch/autograd/anomaly_mode.py:70: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  warnings.warn('Anomaly Detection has been enabled. '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">test-reverse-32bit-warmup12000-embedinit</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/chucooleg/pytorchlightning_test\" target=\"_blank\">https://wandb.ai/chucooleg/pytorchlightning_test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/chucooleg/pytorchlightning_test/runs/3impc0o2\" target=\"_blank\">https://wandb.ai/chucooleg/pytorchlightning_test/runs/3impc0o2</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201111_020810-3impc0o2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params\n",
      "-----------------------------------------------------\n",
      "0 | encdec_model   | EncoderDecoder    | 14 M  \n",
      "1 | loss_criterion | LabelSmoothedLoss | 0     \n",
      "/anaconda/envs/playground/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/playground/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The validation_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/anaconda/envs/playground/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 6 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96d6edc974e42f280216a638465e355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 15,  4,  8, 10,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 10,  8,  4, 15,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 15,  4,  8, 10], device='cuda:0') \n",
      "tgt Y tensor([15,  4,  8, 10,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 16,  5,  4,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  4,  5, 16,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 16,  5,  4], device='cuda:0') \n",
      "tgt Y tensor([ 8, 16,  5,  4,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "Y: tensor([ 1, 19,  8,  6, 16,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 16,  6,  8, 19,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1, 19,  8,  6, 16], device='cuda:0') \n",
      "tgt Y tensor([19,  8,  6, 16,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  5, 16, 16,  6,  2], device='cuda:0') \n",
      "inp X tensor([ 1,  6, 16, 16,  5,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  5, 16, 16,  6], device='cuda:0') \n",
      "tgt Y tensor([ 5, 16, 16,  6,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n",
      "X: tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "Y: tensor([ 1,  8, 15, 19, 14,  2], device='cuda:0') \n",
      "inp X tensor([ 1, 14, 19, 15,  8,  2], device='cuda:0') \n",
      "out Y[:, :-1] tensor([ 1,  8, 15, 19, 14], device='cuda:0') \n",
      "tgt Y tensor([ 8, 15, 19, 14,  2], device='cuda:0') \n",
      "y_hat tensor([1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "## W&B References\n",
    "# https://docs.wandb.com/library/integrations/lightning\n",
    "# colab example\n",
    "# https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch-lightning/Supercharge_your_Training_with_Pytorch_Lightning_%2B_Weights_%26_Biases.ipynb\n",
    "# step by step guide\n",
    "# https://wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-Biases--Vmlldzo2NjQ1Mw\n",
    "\n",
    "\n",
    "hparams = {\n",
    "    'd_model': 512,\n",
    "    'd_ff': 2048,\n",
    "    'max_len': 6,\n",
    "    'num_heads': 2,\n",
    "    'embed_dropout': 0.0,\n",
    "    'attn_wt_dropout': 0.0,\n",
    "    'heads_dropout': 0.0,\n",
    "    'pff_dropout': 0.0,\n",
    "    'N_enc': 2,\n",
    "    'N_dec': 2,\n",
    "    'start_idx': 1,\n",
    "    'padding_idx': 0,\n",
    "    'smoothing_const': 0.1,\n",
    "    'temperature_const': 1.0,\n",
    "    'adam_beta1': 0.9,\n",
    "    'adam_beta2': 0.98,\n",
    "    'adam_epsilon': 1e-9,\n",
    "    'warmup_steps': 12000,\n",
    "    'vocab_size': 20\n",
    "}\n",
    "\n",
    "# model\n",
    "my_transformer = Transformer(hparams)\n",
    "print(pl.core.memory.ModelSummary(my_transformer, mode='full'),'\\n')\n",
    "# data\n",
    "toy_data = ToyDataModule(batch_size=100, V=hparams['vocab_size'], seed=40, context_len=hparams['max_len'], tot_size=500)\n",
    "# logger\n",
    "wd_logger = WandbLogger(name=\"test-reverse-32bit-warmup12000-embedinit\",project='pytorchlightning_test')\n",
    "# wd_logger = WandbLogger(name=\"test-dummy\",project='pytorchlightning_test')\n",
    "# trainer\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1, min_epochs=2, max_epochs=50000, \n",
    "    logger=wd_logger,log_gpu_memory='all',\n",
    "    precision=32, amp_backend='apex', amp_level='O3' )\n",
    "# fit!\n",
    "with torch.autograd.detect_anomaly():\n",
    "    trainer.fit(my_transformer, toy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:playground]",
   "language": "python",
   "name": "conda-env-playground-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
